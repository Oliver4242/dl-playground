{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.000433921813965\n",
      "Loaded data in 4.88782787323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((52950,), (52950,), (52950, 5, 48, 48), numpy.ndarray)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "npzfile = np.load('HCS_48x48.npz')\n",
    "print (\"Loaded data in \" + str(time.time() - start))\n",
    "npzfile.files\n",
    "start = time.time()\n",
    "cell_rows = npzfile['arr_0']\n",
    "X = npzfile['arr_1']\n",
    "Y = npzfile['arr_2']\n",
    "print (\"Loaded data in \" + str(time.time() - start))\n",
    "np.shape(cell_rows), np.shape(Y), np.shape(X), type(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the features of the cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52950, 407)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells_all = pd.read_csv('/home/dueo/data/Genedata/Cells.csv')\n",
    "cells = cells_all.iloc[cell_rows]\n",
    "np.shape(cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AreaShape_Area</th>\n",
       "      <th>AreaShape_Center_X</th>\n",
       "      <th>AreaShape_Center_Y</th>\n",
       "      <th>AreaShape_Compactness</th>\n",
       "      <th>AreaShape_Eccentricity</th>\n",
       "      <th>AreaShape_EulerNumber</th>\n",
       "      <th>AreaShape_Extent</th>\n",
       "      <th>AreaShape_FormFactor</th>\n",
       "      <th>AreaShape_MajorAxisLength</th>\n",
       "      <th>AreaShape_MaxFeretDiameter</th>\n",
       "      <th>...</th>\n",
       "      <th>Texture_Variance_ER_3_0</th>\n",
       "      <th>Texture_Variance_ER_5_0</th>\n",
       "      <th>Texture_Variance_Golgi_Actin_3_0</th>\n",
       "      <th>Texture_Variance_Golgi_Actin_5_0</th>\n",
       "      <th>Texture_Variance_Hoechst_3_0</th>\n",
       "      <th>Texture_Variance_Hoechst_5_0</th>\n",
       "      <th>Texture_Variance_Mito_3_0</th>\n",
       "      <th>Texture_Variance_Mito_5_0</th>\n",
       "      <th>Texture_Variance_Nucleoli_3_0</th>\n",
       "      <th>Texture_Variance_Nucleoli_5_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  5520</td>\n",
       "      <td> 542</td>\n",
       "      <td> 43</td>\n",
       "      <td> 1.297952</td>\n",
       "      <td> 0.837477</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.484295</td>\n",
       "      <td> 0.141449</td>\n",
       "      <td> 118.346136</td>\n",
       "      <td> 142.618372</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.963408</td>\n",
       "      <td> 0.942669</td>\n",
       "      <td> 1.432731</td>\n",
       "      <td> 1.470543</td>\n",
       "      <td> 2.608476</td>\n",
       "      <td> 2.653153</td>\n",
       "      <td> 1.357492</td>\n",
       "      <td> 1.328036</td>\n",
       "      <td> 1.516640</td>\n",
       "      <td> 1.495042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>  6126</td>\n",
       "      <td> 317</td>\n",
       "      <td> 52</td>\n",
       "      <td> 1.230381</td>\n",
       "      <td> 0.769741</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.609977</td>\n",
       "      <td> 0.375944</td>\n",
       "      <td> 116.594822</td>\n",
       "      <td> 130.782262</td>\n",
       "      <td>...</td>\n",
       "      <td> 1.070573</td>\n",
       "      <td> 1.084703</td>\n",
       "      <td> 1.917686</td>\n",
       "      <td> 1.915602</td>\n",
       "      <td> 2.261544</td>\n",
       "      <td> 2.322472</td>\n",
       "      <td> 1.621720</td>\n",
       "      <td> 1.628327</td>\n",
       "      <td> 1.489087</td>\n",
       "      <td> 1.491358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 11618</td>\n",
       "      <td> 438</td>\n",
       "      <td> 82</td>\n",
       "      <td> 1.091077</td>\n",
       "      <td> 0.522378</td>\n",
       "      <td> 1</td>\n",
       "      <td> 0.625431</td>\n",
       "      <td> 0.284604</td>\n",
       "      <td> 136.470704</td>\n",
       "      <td> 152.463110</td>\n",
       "      <td>...</td>\n",
       "      <td> 0.703105</td>\n",
       "      <td> 0.714262</td>\n",
       "      <td> 1.621151</td>\n",
       "      <td> 1.623899</td>\n",
       "      <td> 1.664106</td>\n",
       "      <td> 1.705266</td>\n",
       "      <td> 1.610848</td>\n",
       "      <td> 1.621337</td>\n",
       "      <td> 1.679954</td>\n",
       "      <td> 1.700747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 396 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AreaShape_Area  AreaShape_Center_X  AreaShape_Center_Y  \\\n",
       "0            5520                 542                  43   \n",
       "1            6126                 317                  52   \n",
       "2           11618                 438                  82   \n",
       "\n",
       "   AreaShape_Compactness  AreaShape_Eccentricity  AreaShape_EulerNumber  \\\n",
       "0               1.297952                0.837477                      1   \n",
       "1               1.230381                0.769741                      1   \n",
       "2               1.091077                0.522378                      1   \n",
       "\n",
       "   AreaShape_Extent  AreaShape_FormFactor  AreaShape_MajorAxisLength  \\\n",
       "0          0.484295              0.141449                 118.346136   \n",
       "1          0.609977              0.375944                 116.594822   \n",
       "2          0.625431              0.284604                 136.470704   \n",
       "\n",
       "   AreaShape_MaxFeretDiameter              ...                \\\n",
       "0                  142.618372              ...                 \n",
       "1                  130.782262              ...                 \n",
       "2                  152.463110              ...                 \n",
       "\n",
       "   Texture_Variance_ER_3_0  Texture_Variance_ER_5_0  \\\n",
       "0                 0.963408                 0.942669   \n",
       "1                 1.070573                 1.084703   \n",
       "2                 0.703105                 0.714262   \n",
       "\n",
       "   Texture_Variance_Golgi_Actin_3_0  Texture_Variance_Golgi_Actin_5_0  \\\n",
       "0                          1.432731                          1.470543   \n",
       "1                          1.917686                          1.915602   \n",
       "2                          1.621151                          1.623899   \n",
       "\n",
       "   Texture_Variance_Hoechst_3_0  Texture_Variance_Hoechst_5_0  \\\n",
       "0                      2.608476                      2.653153   \n",
       "1                      2.261544                      2.322472   \n",
       "2                      1.664106                      1.705266   \n",
       "\n",
       "   Texture_Variance_Mito_3_0  Texture_Variance_Mito_5_0  \\\n",
       "0                   1.357492                   1.328036   \n",
       "1                   1.621720                   1.628327   \n",
       "2                   1.610848                   1.621337   \n",
       "\n",
       "   Texture_Variance_Nucleoli_3_0  Texture_Variance_Nucleoli_5_0  \n",
       "0                       1.516640                       1.495042  \n",
       "1                       1.489087                       1.491358  \n",
       "2                       1.679954                       1.700747  \n",
       "\n",
       "[3 rows x 396 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cells.ix[0:2,'AreaShape_Area':]\n",
    "#cells.ix[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the features and imputing NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52950, 396)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features = np.asmatrix(cells.ix[:,'AreaShape_Area':])\n",
    "np.shape(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X_features)\n",
    "X_features = imp.transform(X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xmean = X_features.mean(axis = 0)\n",
    "XStd = np.sqrt(X_features.var(axis=0))\n",
    "X = (X_features-Xmean)/(XStd + 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8173680921031092"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-69.705828219351631, 132.78221451686983, -2.7136455336971616e-18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(X), np.max(X), np.mean(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y = np.asarray(Y,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some examples (after normalization)\n",
    "rows are the different compounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting in training and test-set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1\n",
    "80%, 20% randomly choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Currently a Acc. of 0.8250\n",
    "split = 40000\n",
    "X_train = X[0:split,:]\n",
    "Y_train = Y[0:split]\n",
    "X_test = X[split:,:]\n",
    "Y_test = Y[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 3 (Separation of complete well)\n",
    "Separating a complete well from the training set and use this for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2854"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test = np.asarray(np.recfromtxt ('test_set_data.csv'))\n",
    "np.sum(idx_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    X_train = X[idx_test== False]\n",
    "    X_test = X[idx_test]\n",
    "\n",
    "    Y_train = Y[idx_test== False]\n",
    "    Y_test = Y[idx_test]\n",
    "\n",
    "    X_test.shape, Y_test.shape, X_train.shape, Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NO DMSO and  (Separation of complete well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    Y = Y -1\n",
    "    idx_DMSO = np.asarray(np.recfromtxt ('DMSO_data.csv'))\n",
    "    print('Number of DMSO {}'.format(np.sum(idx_DMSO)))\n",
    "\n",
    "    idx_test_all = np.asarray(np.recfromtxt ('test_set_data.csv'))\n",
    "\n",
    "    idx_train = (idx_test == False) & (idx_DMSO == False)\n",
    "    idx_test  = idx_test & (idx_DMSO == False)\n",
    "\n",
    "    X_train = X[idx_train]\n",
    "    Y_train = Y[idx_train]\n",
    "\n",
    "    X_test = X[idx_test]\n",
    "    Y_test = Y[idx_test]\n",
    "\n",
    "\n",
    "    X_test.shape, Y_test.shape, X_train.shape, Y_train.shape #1964 and 10203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of permutation 1401824775\n"
     ]
    }
   ],
   "source": [
    "# Currently a Acc. of 0.8976\n",
    "if True:\n",
    "    np.random.seed(seed=42)\n",
    "    perm1 = np.random.permutation(len(Y))\n",
    "    print('Sum of permutation {0}'.format(np.sum(perm1))) #1401824775\n",
    "    N_split = int(len(Y) * 0.8)\n",
    "    N_split\n",
    "    idx_train  = perm1[:N_split]\n",
    "    idx_test  = perm1[N_split:]\n",
    "\n",
    "\n",
    "    X_train = X[idx_train,:]\n",
    "    Y_train = Y[idx_train]\n",
    "    X_test = X[idx_test,:]\n",
    "    Y_test = Y[idx_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permuting the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(Y_train))\n",
    "X_train_perm = X_train[perm]\n",
    "Y_train_perm = Y_train[perm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher-LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDA(n_components=None, priors=None)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.lda import LDA\n",
    "clf = LDA()\n",
    "clf.fit(X_train_perm, Y_train_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42360,)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_perm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_lda = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9113314447592068"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_pred_lda == Y_test)/float(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7949,   20,  542,    0],\n",
       "       [  15,  323,   35,   12],\n",
       "       [ 251,   60, 1310,    1],\n",
       "       [   2,    0,    1,   69]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(Y_pred_lda, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_lda = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=500, n_jobs=4,\n",
       "            oob_score=False, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_jobs=4,n_estimators=500,oob_score=False)\n",
    "clf.fit(X_train_perm, Y_train_perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_pred_rf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89150141643059488"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(Y_pred_rf == Y_test)/float(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_prob_RF = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10 Fold X-Validation\n",
    "\n",
    "We use a 10 fold crossvalidation on the training set to find the optimal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling \n",
    "\n",
    "For the SVM we sample so that the classes have equal proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([32566,  1585,  7877,   332]), array([0, 1, 2, 3, 4])), 332)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist = np.histogram(Y_train_perm, bins=[0, 1, 2, 3,4])\n",
    "NMAX = np.min(hist[0])\n",
    "hist, NMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17671,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx3 = np.argwhere(Y_train_perm == 3)\n",
    "idx2 = np.argwhere(Y_train_perm == 2)\n",
    "idx1 = np.argwhere(Y_train_perm == 1)\n",
    "idx0 = np.argwhere(Y_train_perm == 0)[0:7877]\n",
    "idx_d = np.concatenate((idx0,idx1,idx2,idx3))[:,0] #Orderedness is problem in studip k-fold\n",
    "\n",
    "perm_d = np.random.permutation(len(idx_d))\n",
    "idx = idx_d[perm_d]\n",
    "idx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the case of no DSMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    hist = np.histogram(YY, bins=[0, 1, 2, 3,4])\n",
    "    NMAX = np.min(hist[0])\n",
    "    NMAX = 352\n",
    "    hist, NMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    idx2 = np.argwhere(YY == 2)[0:NMAX]\n",
    "    idx1 = np.argwhere(YY == 1)[0:NMAX]\n",
    "    idx0 = np.argwhere(YY == 0)[0:NMAX]\n",
    "    idx_d = np.concatenate((idx0,idx1,idx2))[:,0] #Orderedness is problem in studip k-fold\n",
    "    perm_d = np.random.permutation(len(idx_d))\n",
    "    idx = idx_d[perm_d]\n",
    "    idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17671, 396), (17671,), (42360, 396), (17671,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX1 = X_train_perm[idx]\n",
    "YY1 = Y_train_perm[idx]\n",
    "np.shape(XX1), np.shape(YY1),np.shape(X_train_perm),np.shape(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([7877, 1585, 7877,  332]), array([0, 1, 2, 3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(YY1,  bins=[0, 1, 2, 3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 2, 2, 0, 0, 0, 0, 2], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY1[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eval_10_Fold(C = 0.5):\n",
    "    N = len(XX1)\n",
    "    kf = KFold(N, n_folds=10)\n",
    "    acc = 0.0\n",
    "    rounds = 0.0\n",
    "    for train, test in kf:\n",
    "        model = svm.SVC(kernel='linear', C=C).fit(XX1[train,],YY1[train])\n",
    "        res = model.predict(XX1[test])\n",
    "        acc += sum(res == YY1[test])/float(len(test)) #Accuracy\n",
    "        rounds += 1.0\n",
    "        print('round ={0} C={1} acc (cumulated over the folds) ={2}'.format(rounds, C, acc / rounds))\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Cs = (1e-3,5e-3,1e-2,5e-2,1e-1,1e0,1e+1,1e2,1e3)\n",
    "#Cs = (1e-3,5e-3,1e-2,5e-2,1e-1,1e0,1e+1)\n",
    "#Cs = np.logspace(np.log10(0.001), 2,20)#Schon Komisch, dass man noch ein log drum muss\n",
    "#res = np.zeros(len(Cs))\n",
    "#for i,C in enumerate(Cs):\n",
    "#    res[i] = eval_10_Fold(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.semilogx(Cs,res)\n",
    "#plt.plot(Cs,res)\n",
    "\n",
    "(Cs,res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the test set\n",
    "\n",
    "Training the model on the whole training data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model = svm.SVC(kernel='linear', C=0.01).fit(XX1,YY1)\n",
    "model = svm.SVC(probability=True, kernel='linear', C=0.01).fit(XX1,YY1)\n",
    "#model = svm.SVC(probability=True, C=0.01).fit(X_train,Y_train)\n",
    "#model = svm.SVC(probability=True, C=0.05).fit(XX,YY) #Fit on not sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10590, 396)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17671,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YY1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.predict(X_test)\n",
    "pred_prob_svm = model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88092540132200192"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(pred == Y_test)/float(len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.974,  0.   ,  0.026,  0.   ],\n",
       "       [ 0.862,  0.004,  0.132,  0.002],\n",
       "       [ 0.966,  0.   ,  0.034,  0.   ],\n",
       "       ..., \n",
       "       [ 0.96 ,  0.   ,  0.04 ,  0.   ],\n",
       "       [ 0.862,  0.002,  0.132,  0.004],\n",
       "       [ 0.976,  0.   ,  0.024,  0.   ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob_RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "%load_ext rpy2.ipython\n",
    "%Rpush pred_prob_RF\n",
    "%Rpush pred_prob_lda\n",
    "%Rpush pred_prob_svm\n",
    "%Rpush Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "save(pred_prob_RF, pred_prob_lda, pred_prob_svm, Y_test, file='Test_Like_SIBS_lda_rf_svm.Rdata')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calucation of the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = confusion_matrix(pred, Y_test)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.astype('float') / ((m.sum(axis=0)[np.newaxis,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names_col = ('DMSO True', 'PACLITAXEL True', 'METOCLOPRAMIDE True', 'DIGOXIN True')\n",
    "m = confusion_matrix(pred, Y_test)\n",
    "df = pd.DataFrame(m)\n",
    "df.columns = names_col\n",
    "names = ('DMSO Pred', 'PACLITAXEL Pred', 'METOCLOPRAMIDE Pred', 'DIGOXIN Pred')\n",
    "df.index = names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#cm_normalized = m.astype('float') / ((m.sum(axis=1)[:, np.newaxis]))\n",
    "cm_normalized = m.astype('float') / ((m.sum(axis=0)[np.newaxis,:]))\n",
    "print('Normalized confusion matrix')\n",
    "\n",
    "\n",
    "df = pd.DataFrame(cm_normalized)\n",
    "df.columns = names_col\n",
    "df.index = names\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.mean(cm_normalized[np.diag_indices(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1-np.mean(cm_normalized[np.diag_indices(4)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
