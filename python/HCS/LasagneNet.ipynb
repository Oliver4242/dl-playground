{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780\n",
      "WARNING (theano.sandbox.cuda): Ignoring call to use(1), GPU number 0 is already in use.\n",
      "WARNING:theano.sandbox.cuda:Ignoring call to use(1), GPU number 0 is already in use.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't import dot_parser, loading of dot files will not be possible.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 'Tue Oct  6 21:57:16 2015')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import theano.sandbox.cuda\n",
    "import time\n",
    "theano.sandbox.cuda.use(\"gpu1\"), time.asctime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import skimage\n",
    "skimage.__version__ # We need at least version 0.11.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 9.88800501823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((52950,), (52950,), (52950, 5, 72, 72), numpy.ndarray)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "npzfile = np.load('HCS_72x72.npz')\n",
    "start = time.time()\n",
    "cell_rows = npzfile['arr_0']\n",
    "X = npzfile['arr_1']\n",
    "Y = npzfile['arr_2']\n",
    "print (\"Loaded data in \" + str(time.time() - start))\n",
    "np.shape(cell_rows), np.shape(Y), np.shape(X), type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xmean = X.mean(axis = 0)\n",
    "XStd = np.sqrt(X.var(axis=0))\n",
    "X = (X-Xmean)/(XStd + 0.01)\n",
    "Y = np.asarray(Y,dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_DMSO = np.asarray(np.recfromtxt ('DMSO_data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(idx_DMSO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### No DMSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = Y - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1964, 5, 72, 72), (1964,), (10203, 5, 72, 72), (10203,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_test = np.asarray(np.recfromtxt ('test_set_data.csv'))\n",
    "idx_test\n",
    "X_train = X[(idx_test == False) & (idx_DMSO == False)]\n",
    "X_test = X[idx_test & (idx_DMSO == False)]\n",
    "Y_train = Y[(idx_test == False) & (idx_DMSO == False)]\n",
    "Y_test = Y[idx_test & (idx_DMSO == False)]\n",
    "X_test.shape, Y_test.shape, X_train.shape, Y_train.shape #1964 and 10203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PIXELS = 72\n",
    "conv = (3,3)\n",
    "stride = (1,1)\n",
    "pool = (2,2)\n",
    "\n",
    "num1 = 32\n",
    "num2 = 64\n",
    "num3 = 128\n",
    "p_drop = 0.3\n",
    "\n",
    "CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n"
     ]
    }
   ],
   "source": [
    "from lasagne import layers\n",
    "from lasagne import nonlinearities\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "\n",
    "input_var = T.tensor4('inputs') #This is a variable needed \n",
    "l_in = lasagne.layers.InputLayer(shape=(None, 5, PIXELS, PIXELS), input_var=input_var) #None depend on batch size\n",
    "\n",
    "\n",
    "conv11 = layers.Conv2DLayer(l_in, num_filters=num1, filter_size=conv)\n",
    "conv11 = layers.Conv2DLayer(conv11, num_filters=num1, filter_size=conv)\n",
    "pool1 = layers.MaxPool2DLayer(conv11, pool_size=pool)\n",
    "\n",
    "conv21 = layers.Conv2DLayer(pool1, num_filters=num2, filter_size=conv)\n",
    "conv22 = layers.Conv2DLayer(conv21, num_filters=num2, filter_size=conv)\n",
    "pool2 = layers.MaxPool2DLayer(conv22, pool_size=pool)\n",
    "\n",
    "conv31 = layers.Conv2DLayer(pool2, num_filters=num3, filter_size=conv)\n",
    "conv32 = layers.Conv2DLayer(conv31, num_filters=num3, filter_size=conv)\n",
    "pool3 = layers.MaxPool2DLayer(conv32, pool_size=pool)\n",
    "\n",
    "hidden1 = layers.DenseLayer(layers.dropout(pool3, p_drop), num_units=200)\n",
    "hidden2 = layers.DenseLayer(layers.dropout(hidden1, p_drop), num_units=200)\n",
    "hidden3 = layers.DenseLayer(layers.dropout(hidden2, p_drop), num_units=50)\n",
    "\n",
    "network = layers.DenseLayer(hidden3, num_units=CLASSES, nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Lasagne-0.1dev-py2.7.egg/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n"
     ]
    }
   ],
   "source": [
    "target_var = T.ivector('targets') #The classes 0..9\n",
    "prediction = layers.get_output(network)\n",
    "loss = lasagne.objectives.categorical_crossentropy(prediction, target_var)\n",
    "loss = loss.mean()\n",
    "params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=0.01, momentum=0.9)\n",
    "#print(\"Number of Parameters in network: {}\".format(len(params)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fn = theano.function([input_var, target_var], loss, updates=updates)\n",
    "test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_var)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_var), dtype=theano.config.floatX)\n",
    "val_fn = theano.function([input_var, target_var], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "from skimage import transform as tf\n",
    "\n",
    "#rots = np.deg2rad(np.asarray((90,180,0,5,-5,10,-10)))\n",
    "rots = np.deg2rad(range(0,359))\n",
    "\n",
    "dists = (-5,5)\n",
    "\n",
    "def manipulateTrainingData(Xb):\n",
    "    retX = np.zeros((Xb.shape[0], Xb.shape[1], Xb.shape[2], Xb.shape[3]), dtype='float32')\n",
    "    for i in range(len(Xb)):\n",
    "        rot = rots[np.random.randint(0, len(rots))]\n",
    "\n",
    "        tf_rotate = tf.SimilarityTransform(rotation=rot)\n",
    "        shift_y, shift_x = np.array((X.shape[2], X.shape[3])) / 2.\n",
    "        tf_shift = tf.SimilarityTransform(translation=[-shift_x, -shift_y])\n",
    "        tf_shift_inv = tf.SimilarityTransform(translation=[shift_x, shift_y])\n",
    "        tform_rot = (tf_shift + (tf_rotate + tf_shift_inv))\n",
    "\n",
    "        ## TODO add the transformations\n",
    "        scale = np.random.uniform(0.9,1.10)\n",
    "        d = tf.SimilarityTransform(scale=scale, translation=(np.random.randint(5),np.random.randint(5)))\n",
    "        tform_other = (tform_rot + d)\n",
    "\n",
    "        for c in range(np.shape(X)[1]):\n",
    "            maxAbs = 256.0;np.max(np.abs(Xb[i,c,:,:]))\n",
    "            # Needs at lease 0.11.3\n",
    "            retX[i,c,:,:] = tf.warp(Xb[i,c,:,:], tform_other, preserve_range = True) # \"Float Images\" are only allowed to have values between -1 and 1\n",
    "    return retX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## Batch iterator ###############################\n",
    "# This is just a simple helper function iterating over training data in\n",
    "# mini-batches of a particular size, optionally in random order. It assumes\n",
    "# data is available as numpy arrays. For big datasets, you could load numpy\n",
    "# arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "# own custom data iteration function. For small datasets, you can also copy\n",
    "# them to GPU at once for slightly improved performance. This would involve\n",
    "# several changes in the main program, though, and is not demonstrated here.\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "perf = pd.DataFrame(columns=['train_loss','valid_loss','valid_accuracy', 'time'])\n",
    "perf_test = pd.DataFrame(columns=['epoch','valid_acc_mean','valid_acc_std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We further have to randomize the training set\n",
    "Otherwise the train always on the same images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8162, 5, 72, 72), (8162,), (2041, 5, 72, 72), (2041,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed=42)\n",
    "perm1 = np.random.permutation(len(Y_train))\n",
    "N_split = int(len(Y_train) * 0.8)\n",
    "idx_train1  = perm1[:N_split]\n",
    "idx_val  = perm1[N_split:]\n",
    "\n",
    "X_train1 = X_train[idx_train1]\n",
    "y_train1 = Y_train[idx_train1]\n",
    "X_val = X_train[idx_val]\n",
    "y_val = Y_train[idx_val]\n",
    "np.shape(X_train1), np.shape(y_train1), np.shape(X_val), np.shape(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_func = theano.function([input_var],[test_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Starting\n",
      "Epoch 1 of 510 took 27.900s\n",
      "  training loss:\t\t0.506798\n",
      "  validation loss:\t\t0.178201\n",
      "  validation accuracy:\t\t81.25 %\n",
      "Starting\n",
      "Epoch 2 of 510 took 27.965s\n",
      "  training loss:\t\t0.342076\n",
      "  validation loss:\t\t0.161748\n",
      "  validation accuracy:\t\t87.05 %\n",
      "Starting\n",
      "Epoch 3 of 510 took 27.915s\n",
      "  training loss:\t\t0.330043\n",
      "  validation loss:\t\t0.156604\n",
      "  validation accuracy:\t\t86.05 %\n",
      "Starting\n",
      "Epoch 4 of 510 took 27.847s\n",
      "  training loss:\t\t0.290957\n",
      "  validation loss:\t\t0.142207\n",
      "  validation accuracy:\t\t88.05 %\n",
      "Starting\n",
      "Epoch 5 of 510 took 27.987s\n",
      "  training loss:\t\t0.256998\n",
      "  validation loss:\t\t0.130089\n",
      "  validation accuracy:\t\t89.55 %\n",
      "Starting\n",
      "Epoch 6 of 510 took 28.194s\n",
      "  training loss:\t\t0.241485\n",
      "  validation loss:\t\t0.114549\n",
      "  validation accuracy:\t\t91.30 %\n",
      "Starting\n",
      "Epoch 7 of 510 took 28.248s\n",
      "  training loss:\t\t0.237353\n",
      "  validation loss:\t\t0.114712\n",
      "  validation accuracy:\t\t90.75 %\n",
      "Starting\n",
      "Epoch 8 of 510 took 28.135s\n",
      "  training loss:\t\t0.223102\n",
      "  validation loss:\t\t0.099078\n",
      "  validation accuracy:\t\t92.25 %\n",
      "Starting\n",
      "Epoch 9 of 510 took 28.206s\n",
      "  training loss:\t\t0.211801\n",
      "  validation loss:\t\t0.098875\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Starting\n",
      "Epoch 10 of 510 took 28.039s\n",
      "  training loss:\t\t0.200740\n",
      "  validation loss:\t\t0.090691\n",
      "  validation accuracy:\t\t92.65 %\n",
      "Starting\n",
      "Epoch 11 of 510 took 27.834s\n",
      "  training loss:\t\t0.203016\n",
      "  validation loss:\t\t0.097161\n",
      "  validation accuracy:\t\t92.30 %\n",
      "Starting\n",
      "Epoch 12 of 510 took 27.844s\n",
      "  training loss:\t\t0.194271\n",
      "  validation loss:\t\t0.096010\n",
      "  validation accuracy:\t\t92.20 %\n",
      "Starting\n",
      "Epoch 13 of 510 took 27.903s\n",
      "  training loss:\t\t0.189527\n",
      "  validation loss:\t\t0.090884\n",
      "  validation accuracy:\t\t92.90 %\n",
      "Starting\n",
      "Epoch 14 of 510 took 27.796s\n",
      "  training loss:\t\t0.177606\n",
      "  validation loss:\t\t0.091855\n",
      "  validation accuracy:\t\t92.10 %\n",
      "Starting\n",
      "Epoch 15 of 510 took 28.225s\n",
      "  training loss:\t\t0.179102\n",
      "  validation loss:\t\t0.092322\n",
      "  validation accuracy:\t\t92.50 %\n",
      "Starting\n",
      "Epoch 16 of 510 took 28.201s\n",
      "  training loss:\t\t0.173877\n",
      "  validation loss:\t\t0.088265\n",
      "  validation accuracy:\t\t92.95 %\n",
      "Starting\n",
      "Epoch 17 of 510 took 28.173s\n",
      "  training loss:\t\t0.174338\n",
      "  validation loss:\t\t0.074462\n",
      "  validation accuracy:\t\t94.05 %\n",
      "Starting\n",
      "Epoch 18 of 510 took 28.150s\n",
      "  training loss:\t\t0.168911\n",
      "  validation loss:\t\t0.099573\n",
      "  validation accuracy:\t\t93.15 %\n",
      "Starting\n",
      "Epoch 19 of 510 took 27.905s\n",
      "  training loss:\t\t0.163080\n",
      "  validation loss:\t\t0.087424\n",
      "  validation accuracy:\t\t92.90 %\n",
      "Starting\n",
      "Epoch 20 of 510 took 27.878s\n",
      "  training loss:\t\t0.162737\n",
      "  validation loss:\t\t0.074135\n",
      "  validation accuracy:\t\t93.85 %\n",
      "Starting\n",
      "Epoch 21 of 510 took 27.882s\n",
      "  training loss:\t\t0.149900\n",
      "  validation loss:\t\t0.068806\n",
      "  validation accuracy:\t\t94.35 %\n",
      "Starting\n",
      "Epoch 22 of 510 took 28.200s\n",
      "  training loss:\t\t0.166564\n",
      "  validation loss:\t\t0.105063\n",
      "  validation accuracy:\t\t91.00 %\n",
      "Starting\n",
      "Epoch 23 of 510 took 28.181s\n",
      "  training loss:\t\t0.181800\n",
      "  validation loss:\t\t0.093774\n",
      "  validation accuracy:\t\t92.40 %\n",
      "Starting\n",
      "Epoch 24 of 510 took 28.187s\n",
      "  training loss:\t\t0.166591\n",
      "  validation loss:\t\t0.086073\n",
      "  validation accuracy:\t\t93.35 %\n",
      "Starting\n",
      "Epoch 25 of 510 took 28.235s\n",
      "  training loss:\t\t0.147825\n",
      "  validation loss:\t\t0.067666\n",
      "  validation accuracy:\t\t94.70 %\n",
      "Starting\n",
      "Epoch 26 of 510 took 28.247s\n",
      "  training loss:\t\t0.131724\n",
      "  validation loss:\t\t0.065807\n",
      "  validation accuracy:\t\t95.20 %\n",
      "Starting\n",
      "Epoch 27 of 510 took 28.600s\n",
      "  training loss:\t\t0.129499\n",
      "  validation loss:\t\t0.062125\n",
      "  validation accuracy:\t\t95.10 %\n",
      "Starting\n",
      "Epoch 28 of 510 took 28.279s\n",
      "  training loss:\t\t0.129456\n",
      "  validation loss:\t\t0.061948\n",
      "  validation accuracy:\t\t95.15 %\n",
      "Starting\n",
      "Epoch 29 of 510 took 28.231s\n",
      "  training loss:\t\t0.131583\n",
      "  validation loss:\t\t0.069997\n",
      "  validation accuracy:\t\t94.70 %\n",
      "Starting\n",
      "Epoch 30 of 510 took 28.223s\n",
      "  training loss:\t\t0.121985\n",
      "  validation loss:\t\t0.071028\n",
      "  validation accuracy:\t\t94.65 %\n",
      "Starting\n",
      "Epoch 31 of 510 took 28.249s\n",
      "  training loss:\t\t0.119999\n",
      "  validation loss:\t\t0.069718\n",
      "  validation accuracy:\t\t94.60 %\n",
      "Starting\n",
      "Epoch 32 of 510 took 28.659s\n",
      "  training loss:\t\t0.116898\n",
      "  validation loss:\t\t0.057035\n",
      "  validation accuracy:\t\t95.25 %\n",
      "Starting\n",
      "Epoch 33 of 510 took 28.680s\n",
      "  training loss:\t\t0.115306\n",
      "  validation loss:\t\t0.069558\n",
      "  validation accuracy:\t\t94.20 %\n",
      "Starting\n",
      "Epoch 34 of 510 took 28.307s\n",
      "  training loss:\t\t0.124303\n",
      "  validation loss:\t\t0.061233\n",
      "  validation accuracy:\t\t95.70 %\n",
      "Starting\n",
      "Epoch 35 of 510 took 28.231s\n",
      "  training loss:\t\t0.116685\n",
      "  validation loss:\t\t0.062209\n",
      "  validation accuracy:\t\t94.85 %\n",
      "Starting\n",
      "Epoch 36 of 510 took 28.180s\n",
      "  training loss:\t\t0.110893\n",
      "  validation loss:\t\t0.063899\n",
      "  validation accuracy:\t\t96.05 %\n",
      "Starting\n",
      "Epoch 37 of 510 took 28.183s\n",
      "  training loss:\t\t0.099152\n",
      "  validation loss:\t\t0.051238\n",
      "  validation accuracy:\t\t96.20 %\n",
      "Starting\n",
      "Epoch 38 of 510 took 28.204s\n",
      "  training loss:\t\t0.098304\n",
      "  validation loss:\t\t0.056122\n",
      "  validation accuracy:\t\t95.65 %\n",
      "Starting\n",
      "Epoch 39 of 510 took 28.174s\n",
      "  training loss:\t\t0.105157\n",
      "  validation loss:\t\t0.055831\n",
      "  validation accuracy:\t\t95.95 %\n",
      "Starting\n",
      "Epoch 40 of 510 took 28.202s\n",
      "  training loss:\t\t0.098479\n",
      "  validation loss:\t\t0.059991\n",
      "  validation accuracy:\t\t95.45 %\n",
      "Starting\n",
      "Epoch 41 of 510 took 28.247s\n",
      "  training loss:\t\t0.095638\n",
      "  validation loss:\t\t0.053172\n",
      "  validation accuracy:\t\t96.25 %\n",
      "Starting\n",
      "Epoch 42 of 510 took 28.201s\n",
      "  training loss:\t\t0.085862\n",
      "  validation loss:\t\t0.055387\n",
      "  validation accuracy:\t\t95.80 %\n",
      "Starting\n",
      "Epoch 43 of 510 took 28.209s\n",
      "  training loss:\t\t0.089289\n",
      "  validation loss:\t\t0.062046\n",
      "  validation accuracy:\t\t95.45 %\n",
      "Starting\n",
      "Epoch 44 of 510 took 28.232s\n",
      "  training loss:\t\t0.080769\n",
      "  validation loss:\t\t0.047041\n",
      "  validation accuracy:\t\t96.70 %\n",
      "Starting\n",
      "Epoch 45 of 510 took 28.200s\n",
      "  training loss:\t\t0.092365\n",
      "  validation loss:\t\t0.081412\n",
      "  validation accuracy:\t\t93.65 %\n",
      "Starting\n",
      "Epoch 46 of 510 took 28.209s\n",
      "  training loss:\t\t0.089993\n",
      "  validation loss:\t\t0.050329\n",
      "  validation accuracy:\t\t96.25 %\n",
      "Starting\n",
      "Epoch 47 of 510 took 28.256s\n",
      "  training loss:\t\t0.079319\n",
      "  validation loss:\t\t0.059917\n",
      "  validation accuracy:\t\t96.05 %\n",
      "Starting\n",
      "Epoch 48 of 510 took 28.296s\n",
      "  training loss:\t\t0.074219\n",
      "  validation loss:\t\t0.049641\n",
      "  validation accuracy:\t\t96.55 %\n",
      "Starting\n",
      "Epoch 49 of 510 took 28.203s\n",
      "  training loss:\t\t0.071678\n",
      "  validation loss:\t\t0.043538\n",
      "  validation accuracy:\t\t96.30 %\n",
      "Starting\n",
      "Epoch 50 of 510 took 28.235s\n",
      "  training loss:\t\t0.073352\n",
      "  validation loss:\t\t0.049991\n",
      "  validation accuracy:\t\t96.00 %\n",
      "Starting\n",
      "Epoch 51 of 510 took 28.200s\n",
      "  training loss:\t\t0.070747\n",
      "  validation loss:\t\t0.052505\n",
      "  validation accuracy:\t\t96.25 %\n",
      "Starting\n",
      "Epoch 52 of 510 took 28.206s\n",
      "  training loss:\t\t0.074433\n",
      "  validation loss:\t\t0.042854\n",
      "  validation accuracy:\t\t96.60 %\n",
      "Starting\n",
      "Epoch 53 of 510 took 28.207s\n",
      "  training loss:\t\t0.067166\n",
      "  validation loss:\t\t0.053480\n",
      "  validation accuracy:\t\t95.85 %\n",
      "Starting\n",
      "Epoch 54 of 510 took 28.211s\n",
      "  training loss:\t\t0.067581\n",
      "  validation loss:\t\t0.035830\n",
      "  validation accuracy:\t\t96.90 %\n",
      "Starting\n",
      "Epoch 55 of 510 took 28.225s\n",
      "  training loss:\t\t0.060484\n",
      "  validation loss:\t\t0.042530\n",
      "  validation accuracy:\t\t96.75 %\n",
      "Starting\n",
      "Epoch 56 of 510 took 28.173s\n",
      "  training loss:\t\t0.067833\n",
      "  validation loss:\t\t0.044820\n",
      "  validation accuracy:\t\t97.00 %\n",
      "Starting\n",
      "Epoch 57 of 510 took 28.230s\n",
      "  training loss:\t\t0.065235\n",
      "  validation loss:\t\t0.037149\n",
      "  validation accuracy:\t\t97.00 %\n",
      "Starting\n",
      "Epoch 58 of 510 took 28.217s\n",
      "  training loss:\t\t0.062506\n",
      "  validation loss:\t\t0.045705\n",
      "  validation accuracy:\t\t95.75 %\n",
      "Starting\n",
      "Epoch 59 of 510 took 28.216s\n",
      "  training loss:\t\t0.061663\n",
      "  validation loss:\t\t0.039268\n",
      "  validation accuracy:\t\t97.00 %\n",
      "Starting\n",
      "Epoch 60 of 510 took 28.226s\n",
      "  training loss:\t\t0.060464\n",
      "  validation loss:\t\t0.033437\n",
      "  validation accuracy:\t\t97.30 %\n",
      "Starting\n",
      "Epoch 61 of 510 took 28.258s\n",
      "  training loss:\t\t0.059738\n",
      "  validation loss:\t\t0.030154\n",
      "  validation accuracy:\t\t97.65 %\n",
      "Starting\n",
      "Epoch 62 of 510 took 28.109s\n",
      "  training loss:\t\t0.063981\n",
      "  validation loss:\t\t0.033502\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 63 of 510 took 27.896s\n",
      "  training loss:\t\t0.058171\n",
      "  validation loss:\t\t0.035408\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 64 of 510 took 28.282s\n",
      "  training loss:\t\t0.055973\n",
      "  validation loss:\t\t0.036244\n",
      "  validation accuracy:\t\t97.50 %\n",
      "Starting\n",
      "Epoch 65 of 510 took 28.290s\n",
      "  training loss:\t\t0.049797\n",
      "  validation loss:\t\t0.038791\n",
      "  validation accuracy:\t\t97.05 %\n",
      "Starting\n",
      "Epoch 66 of 510 took 28.333s\n",
      "  training loss:\t\t0.056670\n",
      "  validation loss:\t\t0.049842\n",
      "  validation accuracy:\t\t96.45 %\n",
      "Starting\n",
      "Epoch 67 of 510 took 28.258s\n",
      "  training loss:\t\t0.053551\n",
      "  validation loss:\t\t0.039762\n",
      "  validation accuracy:\t\t96.75 %\n",
      "Starting\n",
      "Epoch 68 of 510 took 28.280s\n",
      "  training loss:\t\t0.060996\n",
      "  validation loss:\t\t0.033186\n",
      "  validation accuracy:\t\t97.55 %\n",
      "Starting\n",
      "Epoch 69 of 510 took 28.199s\n",
      "  training loss:\t\t0.051846\n",
      "  validation loss:\t\t0.037999\n",
      "  validation accuracy:\t\t97.05 %\n",
      "Starting\n",
      "Epoch 70 of 510 took 28.199s\n",
      "  training loss:\t\t0.049244\n",
      "  validation loss:\t\t0.038076\n",
      "  validation accuracy:\t\t96.95 %\n",
      "Starting\n",
      "Epoch 71 of 510 took 28.228s\n",
      "  training loss:\t\t0.048865\n",
      "  validation loss:\t\t0.052392\n",
      "  validation accuracy:\t\t95.95 %\n",
      "Starting\n",
      "Epoch 72 of 510 took 28.244s\n",
      "  training loss:\t\t0.052220\n",
      "  validation loss:\t\t0.038827\n",
      "  validation accuracy:\t\t97.05 %\n",
      "Starting\n",
      "Epoch 73 of 510 took 28.212s\n",
      "  training loss:\t\t0.047397\n",
      "  validation loss:\t\t0.046946\n",
      "  validation accuracy:\t\t97.10 %\n",
      "Starting\n",
      "Epoch 74 of 510 took 28.155s\n",
      "  training loss:\t\t0.050034\n",
      "  validation loss:\t\t0.033284\n",
      "  validation accuracy:\t\t97.55 %\n",
      "Starting\n",
      "Epoch 75 of 510 took 28.176s\n",
      "  training loss:\t\t0.049962\n",
      "  validation loss:\t\t0.036277\n",
      "  validation accuracy:\t\t96.85 %\n",
      "Starting\n",
      "Epoch 76 of 510 took 28.185s\n",
      "  training loss:\t\t0.045748\n",
      "  validation loss:\t\t0.105466\n",
      "  validation accuracy:\t\t92.60 %\n",
      "Starting\n",
      "Epoch 77 of 510 took 27.994s\n",
      "  training loss:\t\t0.048329\n",
      "  validation loss:\t\t0.050571\n",
      "  validation accuracy:\t\t95.95 %\n",
      "Starting\n",
      "Epoch 78 of 510 took 27.865s\n",
      "  training loss:\t\t0.044245\n",
      "  validation loss:\t\t0.041460\n",
      "  validation accuracy:\t\t96.85 %\n",
      "Starting\n",
      "Epoch 79 of 510 took 27.909s\n",
      "  training loss:\t\t0.048132\n",
      "  validation loss:\t\t0.035817\n",
      "  validation accuracy:\t\t97.35 %\n",
      "Starting\n",
      "Epoch 80 of 510 took 28.222s\n",
      "  training loss:\t\t0.041828\n",
      "  validation loss:\t\t0.038529\n",
      "  validation accuracy:\t\t97.05 %\n",
      "Starting\n",
      "Epoch 81 of 510 took 28.277s\n",
      "  training loss:\t\t0.048122\n",
      "  validation loss:\t\t0.038504\n",
      "  validation accuracy:\t\t97.35 %\n",
      "Starting\n",
      "Epoch 82 of 510 took 28.287s\n",
      "  training loss:\t\t0.039736\n",
      "  validation loss:\t\t0.029676\n",
      "  validation accuracy:\t\t98.00 %\n",
      "Starting\n",
      "Epoch 83 of 510 took 28.279s\n",
      "  training loss:\t\t0.041984\n",
      "  validation loss:\t\t0.032144\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Starting\n",
      "Epoch 84 of 510 took 28.229s\n",
      "  training loss:\t\t0.043181\n",
      "  validation loss:\t\t0.041796\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 85 of 510 took 28.244s\n",
      "  training loss:\t\t0.042790\n",
      "  validation loss:\t\t0.034627\n",
      "  validation accuracy:\t\t97.75 %\n",
      "Starting\n",
      "Epoch 86 of 510 took 28.238s\n",
      "  training loss:\t\t0.036255\n",
      "  validation loss:\t\t0.033196\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 87 of 510 took 28.226s\n",
      "  training loss:\t\t0.037808\n",
      "  validation loss:\t\t0.040874\n",
      "  validation accuracy:\t\t97.50 %\n",
      "Starting\n",
      "Epoch 88 of 510 took 28.214s\n",
      "  training loss:\t\t0.039284\n",
      "  validation loss:\t\t0.060316\n",
      "  validation accuracy:\t\t96.60 %\n",
      "Starting\n",
      "Epoch 89 of 510 took 28.186s\n",
      "  training loss:\t\t0.039968\n",
      "  validation loss:\t\t0.037920\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Starting\n",
      "Epoch 90 of 510 took 28.190s\n",
      "  training loss:\t\t0.037130\n",
      "  validation loss:\t\t0.039860\n",
      "  validation accuracy:\t\t97.00 %\n",
      "Starting\n",
      "Epoch 91 of 510 took 28.197s\n",
      "  training loss:\t\t0.041244\n",
      "  validation loss:\t\t0.034013\n",
      "  validation accuracy:\t\t97.35 %\n",
      "Starting\n",
      "Epoch 92 of 510 took 28.188s\n",
      "  training loss:\t\t0.046976\n",
      "  validation loss:\t\t0.036108\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 93 of 510 took 28.188s\n",
      "  training loss:\t\t0.033711\n",
      "  validation loss:\t\t0.030499\n",
      "  validation accuracy:\t\t98.00 %\n",
      "Starting\n",
      "Epoch 94 of 510 took 28.249s\n",
      "  training loss:\t\t0.035272\n",
      "  validation loss:\t\t0.032582\n",
      "  validation accuracy:\t\t97.65 %\n",
      "Starting\n",
      "Epoch 95 of 510 took 28.261s\n",
      "  training loss:\t\t0.032241\n",
      "  validation loss:\t\t0.031591\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Starting\n",
      "Epoch 96 of 510 took 28.235s\n",
      "  training loss:\t\t0.037945\n",
      "  validation loss:\t\t0.031737\n",
      "  validation accuracy:\t\t97.80 %\n",
      "Starting\n",
      "Epoch 97 of 510 took 28.246s\n",
      "  training loss:\t\t0.033171\n",
      "  validation loss:\t\t0.048580\n",
      "  validation accuracy:\t\t96.20 %\n",
      "Starting\n",
      "Epoch 98 of 510 took 28.242s\n",
      "  training loss:\t\t0.038001\n",
      "  validation loss:\t\t0.036537\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 99 of 510 took 28.348s\n",
      "  training loss:\t\t0.030519\n",
      "  validation loss:\t\t0.033502\n",
      "  validation accuracy:\t\t97.85 %\n",
      "Starting\n",
      "Epoch 100 of 510 took 28.306s\n",
      "  training loss:\t\t0.033687\n",
      "  validation loss:\t\t0.042861\n",
      "  validation accuracy:\t\t97.45 %\n",
      "Starting\n",
      "Epoch 101 of 510 took 28.216s\n",
      "  training loss:\t\t0.037906\n",
      "  validation loss:\t\t0.033441\n",
      "  validation accuracy:\t\t97.90 %\n",
      "Starting\n",
      "Epoch 102 of 510 took 28.229s\n",
      "  training loss:\t\t0.034462\n",
      "  validation loss:\t\t0.035177\n",
      "  validation accuracy:\t\t97.75 %\n",
      "Starting\n",
      "Epoch 103 of 510 took 28.200s\n",
      "  training loss:\t\t0.035028\n",
      "  validation loss:\t\t0.034018\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Starting\n",
      "Epoch 104 of 510 took 28.221s\n",
      "  training loss:\t\t0.031813\n",
      "  validation loss:\t\t0.031659\n",
      "  validation accuracy:\t\t97.80 %\n",
      "Starting\n",
      "Epoch 105 of 510 took 28.194s\n",
      "  training loss:\t\t0.033177\n",
      "  validation loss:\t\t0.028413\n",
      "  validation accuracy:\t\t98.15 %\n",
      "Starting\n",
      "Epoch 106 of 510 took 28.170s\n",
      "  training loss:\t\t0.034656\n",
      "  validation loss:\t\t0.029044\n",
      "  validation accuracy:\t\t97.75 %\n",
      "Starting\n",
      "Epoch 107 of 510 took 28.157s\n",
      "  training loss:\t\t0.024662\n",
      "  validation loss:\t\t0.050111\n",
      "  validation accuracy:\t\t97.25 %\n",
      "Starting\n",
      "Epoch 108 of 510 took 28.180s\n",
      "  training loss:\t\t0.032006\n",
      "  validation loss:\t\t0.032237\n",
      "  validation accuracy:\t\t97.90 %\n",
      "Starting\n",
      "Epoch 109 of 510 took 28.178s\n",
      "  training loss:\t\t0.038186\n",
      "  validation loss:\t\t0.036294\n",
      "  validation accuracy:\t\t97.65 %\n",
      "Starting\n",
      "Epoch 110 of 510 took 28.193s\n",
      "  training loss:\t\t0.032865\n",
      "  validation loss:\t\t0.038165\n",
      "  validation accuracy:\t\t97.15 %\n",
      "Starting\n",
      "Epoch 111 of 510 took 28.285s\n",
      "  training loss:\t\t0.029054\n",
      "  validation loss:\t\t0.035620\n",
      "  validation accuracy:\t\t97.60 %\n",
      "Starting\n",
      "Epoch 112 of 510 took 28.304s\n",
      "  training loss:\t\t0.029166\n",
      "  validation loss:\t\t0.030110\n",
      "  validation accuracy:\t\t97.85 %\n",
      "Starting\n",
      "Epoch 113 of 510 took 28.285s\n",
      "  training loss:\t\t0.028744\n",
      "  validation loss:\t\t0.030497\n",
      "  validation accuracy:\t\t98.20 %\n",
      "Starting\n",
      "Epoch 114 of 510 took 28.254s\n",
      "  training loss:\t\t0.030050\n",
      "  validation loss:\t\t0.033969\n",
      "  validation accuracy:\t\t97.55 %\n",
      "Starting\n",
      "Epoch 115 of 510 took 28.256s\n",
      "  training loss:\t\t0.029040\n",
      "  validation loss:\t\t0.037233\n",
      "  validation accuracy:\t\t97.55 %\n",
      "Starting\n",
      "Epoch 116 of 510 took 28.288s\n",
      "  training loss:\t\t0.030373\n",
      "  validation loss:\t\t0.036135\n",
      "  validation accuracy:\t\t97.50 %\n",
      "Starting\n",
      "Epoch 117 of 510 took 28.265s\n",
      "  training loss:\t\t0.025134\n",
      "  validation loss:\t\t0.042820\n",
      "  validation accuracy:\t\t97.00 %\n",
      "Starting\n",
      "Epoch 118 of 510 took 28.259s\n",
      "  training loss:\t\t0.031819\n",
      "  validation loss:\t\t0.032949\n",
      "  validation accuracy:\t\t98.30 %\n",
      "Starting\n",
      "Epoch 119 of 510 took 28.246s\n",
      "  training loss:\t\t0.026472\n",
      "  validation loss:\t\t0.028467\n",
      "  validation accuracy:\t\t98.00 %\n",
      "Starting\n",
      "Epoch 120 of 510 took 28.241s\n",
      "  training loss:\t\t0.029492\n",
      "  validation loss:\t\t0.029778\n",
      "  validation accuracy:\t\t98.00 %\n",
      "Starting\n",
      "Epoch 121 of 510 took 28.209s\n",
      "  training loss:\t\t0.026260\n",
      "  validation loss:\t\t0.037096\n",
      "  validation accuracy:\t\t97.90 %\n",
      "Starting\n",
      "Epoch 122 of 510 took 28.196s\n",
      "  training loss:\t\t0.030690\n",
      "  validation loss:\t\t0.033490\n",
      "  validation accuracy:\t\t97.70 %\n",
      "Starting\n",
      "Epoch 123 of 510 took 28.277s\n",
      "  training loss:\t\t0.024648\n",
      "  validation loss:\t\t0.047066\n",
      "  validation accuracy:\t\t96.85 %\n",
      "Starting\n",
      "Epoch 124 of 510 took 28.212s\n",
      "  training loss:\t\t0.026517\n",
      "  validation loss:\t\t0.031537\n",
      "  validation accuracy:\t\t98.15 %\n",
      "Starting\n",
      "Epoch 125 of 510 took 28.177s\n",
      "  training loss:\t\t0.026855\n",
      "  validation loss:\t\t0.028998\n",
      "  validation accuracy:\t\t97.75 %\n",
      "Starting"
     ]
    }
   ],
   "source": [
    "import cPickle as pickle\n",
    "# We iterate over epochs:\n",
    "num_epochs = 510\n",
    "print('Starting')\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    print('Starting')\n",
    "    for batch in iterate_minibatches(X_train1, y_train1, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        #print('Manipulating inputs '.format(np.shape(inputs)))\n",
    "        dd = manipulateTrainingData(inputs)\n",
    "        train_err += train_fn(dd, targets)\n",
    "        train_batches += 1\n",
    "    \n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 50, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    \n",
    "    time_taken = time.time() - start_time\n",
    "    perf.loc[epoch] = [train_err / train_batches, val_err / train_batches, val_acc / val_batches, time_taken]\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time_taken))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / train_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "    \n",
    "    perf.to_csv('/home/dueo/Dropbox/Server_Sync/current_training.csv')\n",
    "    \n",
    "    ## Testing on the testset\n",
    "    avg = []\n",
    "    for batch in iterate_minibatches(X_test, Y_test, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        res = pred_func(inputs)\n",
    "        avg.append(np.mean(np.argmax(res[0],axis=1) == targets))\n",
    "        perf_test.loc[epoch] = [epoch, np.mean(avg), np.std(avg)]\n",
    "    perf_test.to_csv('/home/dueo/Dropbox/Server_Sync/current_test.csv')\n",
    "    \n",
    "    # Optionally, you could now dump the network weights to a file like this:\n",
    "    # np.savez('model.npz', *lasagne.layers.get_all_param_values(network))\n",
    "    #\n",
    "    # And load them again later on like this:\n",
    "    # with np.load('model.npz') as f:\n",
    "    #     param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "    # lasagne.layers.set_all_param_values(network, param_values)\n",
    "    if (epoch % 10 == 0):\n",
    "        np.savez('net_PAPER_aug_epoch{}_72x72large_net.pickle'.format(epoch), lasagne.layers.get_all_param_values(network))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
