{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following code is taken from\n",
    "\n",
    "https://github.com/Lasagne/Lasagne/blob/master/examples/recurrent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links:\n",
    "* http://larseidnes.com/2015/10/13/auto-generating-clickbait-with-recurrent-neural-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X.shape 1759\n",
    "idx_train = 1055\n",
    "idx_val   = 1055 + 350"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     id  X2  X3  X4  X5  X6  X7  X8  X9  X10    ...     X29  X30  X31  X32  \\\n",
       " 0  2358   0   0   0   0   0   0   0  -2   -2    ...      -2    1    1   -2   \n",
       " 1  2359   0   0   0  -2   1   0   0   0   -2    ...       1   -1    1    1   \n",
       " 2  2360   0   0   0   0   1   0  -2  -2   -1    ...      -2    1    1    0   \n",
       " 3  2361   0   0   0   0  -1  -2  -1   1   -2    ...       0   -2   -1    1   \n",
       " \n",
       "    X33  X34  X35  X36  X37  playerId  \n",
       " 0    1   -2    1    0   -1      1327  \n",
       " 1    1    1   -1   -2    1      1327  \n",
       " 2   -2   -2    1   -2    1      1327  \n",
       " 3    1    0    1    0    1      1327  \n",
       " \n",
       " [4 rows x 38 columns], (1759, 38))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Zeitreihen_id.csv', sep =\" \")\n",
    "df[0:4], df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1759, 36), (1759,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = np.asarray(df.ix[:,'X2':'X37']) + 2 #+2 so that all goes from 0 to 3\n",
    "y_ = df.ix[:,'playerId']\n",
    "X_.shape, y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([13734, 20629, 15462, 13499,     0]), array([0, 1, 2, 3, 4, 5])),\n",
       " {0, 1, 2, 3})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(X_, bins=(0,1,2,3,4,5)),set(np.reshape(X_,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 52,  26,  33,  28, 162,  57,  40,  21,  58,  28,  34,  71, 140,\n",
       "         47,  52,  26, 622,  93,  21,  52,  96,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0]),\n",
       " array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_set = list(set(y_))\n",
    "num_to_ix = { ch:i for i,ch in enumerate(y_set) }\n",
    "ix_to_num = { i:ch for i,ch in enumerate(y_set) }\n",
    "y_d = np.asarray([num_to_ix[y_[i]] for i in range(len(y_))],dtype='int32')\n",
    "np.histogram(y_d, bins=range(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### shuffeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.random.permutation(X_.shape[0])\n",
    "y = y_d[idx]\n",
    "X = X_[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LENGTH = X_.shape[1]\n",
    "N_LSTM = 128\n",
    "N_BATCH = 100\n",
    "num_epochs=10\n",
    "num_classes  = len(ix_to_num)\n",
    "num_inputs  = 4 #Alphabet\n",
    "LENGTH\n",
    "GRAD_CLIP = 100\n",
    "LEARNING_RATE = 0.01\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Builded network ...\n"
     ]
    }
   ],
   "source": [
    "#We leave the batch size open in the definition of the network\n",
    "l_in = InputLayer(shape=(None, LENGTH,1)) #Example: (10, 36, 1)\n",
    "current_bs = l_in.input_var.shape[0]\n",
    "\n",
    "l_lstm = LSTMLayer(l_in, N_LSTM, grad_clipping=GRAD_CLIP, nonlinearity=lasagne.nonlinearities.tanh) \n",
    "#Shape (Batches, LENGTH, N_LSTM) Example: (10, 36, 12)\n",
    "\n",
    "l_lstm_1 =  LSTMLayer(l_lstm, N_LSTM, grad_clipping=GRAD_CLIP, nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "# See https://github.com/Lasagne/Recipes/blob/master/examples/lstm_text_generation.py\n",
    "# The output of the sliced layer will then be of size (batch_size, N_HIDDEN)\n",
    "l_shp = lasagne.layers.SliceLayer(l_lstm_1, -1, 1)\n",
    "# Shape (10,12)\n",
    "\n",
    "l_out = DenseLayer(l_shp, num_units=num_classes, W = lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax) \n",
    "#Shape (10, 21)\n",
    "#l_out = ReshapeLayer(l_dense, (current_bs, LENGTH, num_classes)) #(10, 36, 21)\n",
    "\n",
    "print(\"Builded network ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/theano/scan_module/scan.py:1019: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n",
      "/Library/Python/2.7/site-packages/theano/scan_module/scan_perform_ext.py:135: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((10, 21),\n",
       " array([ 0.04835788,  0.04828471,  0.04743727,  0.04766143,  0.04749208,\n",
       "         0.04774138,  0.04777082,  0.04758632,  0.04773088,  0.04762105,\n",
       "         0.04810425,  0.04737234,  0.04788976,  0.04746125,  0.0471393 ,\n",
       "         0.04714382,  0.04774454,  0.04711527,  0.04757831,  0.04730505,\n",
       "         0.04746228], dtype=float32),\n",
       " 1.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the network (are the number of layers like what one expects)\n",
    "preds = theano.function([l_in.input_var], lasagne.layers.get_output(l_out))\n",
    "Xd = np.asarray(np.reshape(X[0:10,:],(10,36,1)), dtype='float32')\n",
    "res = preds(Xd)\n",
    "res.shape, res[0], np.sum(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lasagne.layers.get_output produces a variable for the output of the net\n",
    "target_values = T.ivector('target_output')\n",
    "network_output = lasagne.layers.get_output(l_out)\n",
    "cost = T.nnet.categorical_crossentropy(network_output,target_values).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "yd = y[0:10]\n",
    "cost_values = theano.function([l_in.input_var, target_values], cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(3.045325994491577, dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost_values(Xd,yd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n"
     ]
    }
   ],
   "source": [
    "all_params = lasagne.layers.get_all_params(l_out)\n",
    "# Compute AdaGrad updates for training\n",
    "print(\"Computing updates ...\")\n",
    "updates = lasagne.updates.adagrad(cost, all_params, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = theano.function([l_in.input_var, target_values], cost, updates=updates, allow_input_downcast=True)\n",
    "compute_cost = theano.function([l_in.input_var, target_values], cost, allow_input_downcast=True)\n",
    "probs = theano.function([l_in.input_var],network_output,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_prediction = lasagne.layers.get_output(l_out, deterministic=True)\n",
    "test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,target_values)\n",
    "test_loss = test_loss.mean()\n",
    "# As a bonus, also create an expression for the classification accuracy:\n",
    "test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), target_values), dtype=theano.config.floatX)\n",
    "val_fn = theano.function([l_in.input_var, target_values], [test_loss, test_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1055, 36, 1), (1055,), (350, 36, 1), (350,), (354, 36, 1), (354,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ = np.asarray(np.reshape(X,(X.shape[0],X.shape[1],1)), dtype='float32')\n",
    "\n",
    "X_train = X_[0:idx_train,:]\n",
    "y_train = y[0:idx_train]\n",
    "\n",
    "X_val = X_[idx_train:idx_val]\n",
    "y_val = y[idx_train:idx_val]\n",
    "\n",
    "X_test = X_[idx_val:]\n",
    "y_test = y[idx_val:]\n",
    "\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################## Batch iterator ###############################\n",
    "# This is just a simple helper function iterating over training data in\n",
    "# mini-batches of a particular size, optionally in random order. It assumes\n",
    "# data is available as numpy arrays. For big datasets, you could load numpy\n",
    "# arrays as memory-mapped files (np.load(..., mmap_mode='r')), or write your\n",
    "# own custom data iteration function. For small datasets, you can also copy\n",
    "# them to GPU at once for slightly improved performance. This would involve\n",
    "# several changes in the main program, though, and is not demonstrated here.\n",
    "\n",
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "perf = pd.DataFrame(columns=['train_loss','valid_loss','valid_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 300 took 4.011s\n",
      "  training loss:\t\t2.354967\n",
      "  validation loss:\t\t2.513048\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 2 of 300 took 4.051s\n",
      "  training loss:\t\t2.331475\n",
      "  validation loss:\t\t2.490508\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 3 of 300 took 3.980s\n",
      "  training loss:\t\t2.295682\n",
      "  validation loss:\t\t2.433271\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 4 of 300 took 3.986s\n",
      "  training loss:\t\t2.314661\n",
      "  validation loss:\t\t2.431298\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 5 of 300 took 3.994s\n",
      "  training loss:\t\t2.309992\n",
      "  validation loss:\t\t2.492824\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 6 of 300 took 3.965s\n",
      "  training loss:\t\t2.308680\n",
      "  validation loss:\t\t2.448463\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 7 of 300 took 3.987s\n",
      "  training loss:\t\t2.289183\n",
      "  validation loss:\t\t2.430856\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 8 of 300 took 3.975s\n",
      "  training loss:\t\t2.292264\n",
      "  validation loss:\t\t2.428428\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 9 of 300 took 4.009s\n",
      "  training loss:\t\t2.270938\n",
      "  validation loss:\t\t2.462603\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 10 of 300 took 4.004s\n",
      "  training loss:\t\t2.274748\n",
      "  validation loss:\t\t2.425599\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 11 of 300 took 4.036s\n",
      "  training loss:\t\t2.255015\n",
      "  validation loss:\t\t2.441556\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 12 of 300 took 3.994s\n",
      "  training loss:\t\t2.265961\n",
      "  validation loss:\t\t2.455976\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 13 of 300 took 4.005s\n",
      "  training loss:\t\t2.267202\n",
      "  validation loss:\t\t2.435314\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 14 of 300 took 4.001s\n",
      "  training loss:\t\t2.258624\n",
      "  validation loss:\t\t2.437713\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 15 of 300 took 4.000s\n",
      "  training loss:\t\t2.259706\n",
      "  validation loss:\t\t2.420190\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 16 of 300 took 4.018s\n",
      "  training loss:\t\t2.253013\n",
      "  validation loss:\t\t2.436635\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 17 of 300 took 4.006s\n",
      "  training loss:\t\t2.245905\n",
      "  validation loss:\t\t2.425049\n",
      "  validation accuracy:\t\t31.20 %\n",
      "Epoch 18 of 300 took 3.991s\n",
      "  training loss:\t\t2.243006\n",
      "  validation loss:\t\t2.425354\n",
      "  validation accuracy:\t\t29.60 %\n",
      "Epoch 19 of 300 took 4.005s\n",
      "  training loss:\t\t2.237843\n",
      "  validation loss:\t\t2.419324\n",
      "  validation accuracy:\t\t31.60 %\n",
      "Epoch 20 of 300 took 3.982s\n",
      "  training loss:\t\t2.244691\n",
      "  validation loss:\t\t2.467243\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 21 of 300 took 3.994s\n",
      "  training loss:\t\t2.217055\n",
      "  validation loss:\t\t2.430859\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 22 of 300 took 4.006s\n",
      "  training loss:\t\t2.244092\n",
      "  validation loss:\t\t2.428697\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 23 of 300 took 4.005s\n",
      "  training loss:\t\t2.231223\n",
      "  validation loss:\t\t2.438019\n",
      "  validation accuracy:\t\t30.00 %\n",
      "Epoch 24 of 300 took 3.998s\n",
      "  training loss:\t\t2.219187\n",
      "  validation loss:\t\t2.473132\n",
      "  validation accuracy:\t\t29.60 %\n",
      "Epoch 25 of 300 took 4.019s\n",
      "  training loss:\t\t2.209402\n",
      "  validation loss:\t\t2.434270\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 26 of 300 took 4.046s\n",
      "  training loss:\t\t2.228136\n",
      "  validation loss:\t\t2.437081\n",
      "  validation accuracy:\t\t30.80 %\n",
      "Epoch 27 of 300 took 4.055s\n",
      "  training loss:\t\t2.224954\n",
      "  validation loss:\t\t2.429508\n",
      "  validation accuracy:\t\t30.40 %\n",
      "Epoch 28 of 300 took 4.063s"
     ]
    }
   ],
   "source": [
    "num_epochs = 300\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train, 100, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train(inputs, targets)\n",
    "        train_batches += 1\n",
    "        \n",
    "    # And a full pass over the validation data:\n",
    "    val_err = 0\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, 250, shuffle=False):\n",
    "        inputs, targets = batch\n",
    "        err, acc = val_fn(inputs, targets)\n",
    "        val_err += err\n",
    "        val_acc += acc\n",
    "        val_batches += 1\n",
    "    \n",
    "    perf.loc[epoch] = [train_err / train_batches, val_err / val_batches, val_acc / val_batches]\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss:\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  validation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes.AxesSubplot at 0x113f8ef90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAXIAAAEKCAYAAAAPVd6lAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJzt3XmcHAWZ//HPJCEJlyCiIBAdFUEOV1BEPIAHUTR4rqsC\n",
       "nqirvvzpoqur6MpP47E/r5/iii7q7gp4AN4KCiq6IKwHXoRDhJVIuEUgEDSBBJLeP55qp6bz1HRX\n",
       "T08/NdPf9+vVr+nqqq7+9vT0U1VP1VSBiIiIiIiIiIiIiIiIiIiIiIiIiIhIbTsA5wN3Ah9JzpLl\n",
       "ZOB903j+icBxg4kyY/4MjM/AtJJsQXYA6dtK4AHABmANcDbwhuJ+Xa8B/gTcZ1DhZqFWcevX6wYV\n",
       "pORA4Kzi/hiwBROfbwvYE7i+xvy2nqFpJdm87ADStxbwTPwL92hgP+qvEY7hfwMPBn7XZ465tDIw\n",
       "1ufzZup7dAH++W4N7FU8tk0xfB8mF/H5M5RBZgEV8rnhRuB7wN7F8AHAT4HbgeXAwaVpzwPeD/w3\n",
       "vnZ3CvAy4G345vSTgYXAx4EbitvxxWMAhheQtwE3AZ8D3g18FfgC3p65BHg48A7gZuAa4KmlDK8A\n",
       "Li+mXYFvEbS15//m4rk3AkeXxm8OfBTfIrkDL3aLe3jfnfYFflNkOL00D4rXu6Bj+o3AQ4v7J+Ot\n",
       "lLOAvwCHMLk10+093A84E1gN/AL/PDpfr1PnQmYZ8DX8d74aeDnwWOBn+Pu/ETgB2GyK9/Ap4Dv4\n",
       "7+DnpXF1pz0MuBL/PD4F/Bh4VZf3IyLA1cChxf0lwGXAe4CdgVuBpxfjnlIM368YPg8vgnvgC/IF\n",
       "wEnAe0vzfi9eELcvbj8pjTfgHuADeJFYjBeVu/BiPR9fOKzEC/l84O+BP5TmfzjwkOL+QfgCZd+O\n",
       "+S8rnru0GL9NMf5TwH8BDyzyH4AvZKre9/ZsaiG+cHlj8Rp/B6wvvcej6V7I7wAeXwwvYvLvsNt7\n",
       "OB04Ff/d7QFci++jmMp4kaG98rWsyPzsYngxvmW2PxNbWZcX77HqPdyKb8nNB74InNbHtNvjC5Ln\n",
       "Fq97TJHrlV3ej4jghfLP+NrXSuCT+Jf5WODzHdN+D1/rBjgXLwJlJzF5R99VTBRE8DWuq4v7Bqxj\n",
       "Yg2dYn7fLw0/q8jWXovcGi8MVT34b+IFoD3/tUzeWryZiQK1FnhkMI9u77vsIHxLo6y8sDqa7oX8\n",
       "5I7x5d/hVO9hPl7oHl4a977g9TqNs2khP6/Lc94EfKM0XH4PJwGfLY1byuT2Wq/Tvgz/3ZVdiwr5\n",
       "UM2l/uaoaQHPwddOyx4MvAAvpm0LOqa7rsu8d8LXWNuuLR5ruwUvRmV/Kt2/C1+Da5WGAbbCN82X\n",
       "4u2Yh+OFaQu8HdN2G15I2tYWz90eX1itCDL38r7bdmLTQn5NMF2VFt13Mla9h/sXucqfQZ0dlmWd\n",
       "z9sN+BjwGPx3ugD41RTPv7l0/64iX91pdwpy9Pt+pE/qkc891+J90/uWblsDHy5N0+3ojBuZfOjZ\n",
       "g4rHqp5f52iPRcDXizwPKPKdRW87Gm8F7gZ2Dcb18r7bbsJbMWUPLt1fgxfCth17yAa9/R5uAe7F\n",
       "22FtSyqm7fZana93It5O2RVv47yTmf+O3wjsUhoe6xiWIVAhn3u+iK+VHoZvxi/GN/XLhauzaHYO\n",
       "n4YfAdPukb8LL5JV6hztsbC43YqvsS4tsvZiI75z9WN4j3w+3qdeSG/vu+2neDE9Bu/zPw/fUdh2\n",
       "MX6UyKOY2AdQFr3fsYrHO23A2x3L8B23jwBeSv1DH6PX2gpvaa0t5jvVIZF1PrOppj0Lb3U9B98C\n",
       "eD29L/hkQFTI557r8S/VP+PtjmuBtzD5yxitUZcfez++SX5JcftV8Vivz6+aBrzQHAN8BVgFHAV8\n",
       "u8tzy/4JuBT4Jd6++AD+d1z1vqO/8Xvw4n10MY8X4lsJbf+D98t/iB+NcUFHpqr32zlNlTfga8x/\n",
       "xHcMn8amrapItwz/BLwIb199Ft+pWpWp22fW67S34i2tDxf398D/XtZN8T5kyBYDF+KHcl2Of2ki\n",
       "nwB+j6/J7FsxjYjEPoTvUJwL5uH7H6Y69FMStHuFC/DjR5/UMf5wJv777HHFNCJSbXfgb/CtpP3x\n",
       "vvmzp3xGsx0GbIvv/zgOL+SLUhNJpS3wzdk9Ox7/NHBEafgK/NwdIhLbD9+CXYMfX39sbpxpezfe\n",
       "VrkT/4ekx049uWSYh7dW/kx8BMCZwBNKwz/ED38SEZEh6GVn50ZgH/yQooPwIwE6de7Vns7Jh0RE\n",
       "pIY6/xC0Gvguvll4XunxG5h8HOwubPrPFu3pdgoeFxGRaiuI/3eiZ9vjOzHAj3k9n4nze7SVd3Ye\n",
       "QPXOziaupS/LDhBYlh0gsCw7QIVl2QECy7IDBJZlBwgsyw4QWJYdoELX2tltjfyB+HGu84rbF4Af\n",
       "Aa8txn8GL+KH4+fnWIOf2W62GM8OEBjPDhAYzw5QYTw7QGA8O0BgPDtAYDw7QGA8O0C/uhXyS/Ez\n",
       "qnX6TMfwGwYTR0REmqyJrRXLDhCw7AAByw5QwbIDBCw7QMCyAwQsO0DAsgNUaFTtbFQYEZFZomvt\n",
       "HPVzrVh2gIBlBwhYdoAKlh0gYNkBApYdIGDZAQKWHaBfo17IRUSkBrVWRETqU2tFRGSuG/VCbtkB\n",
       "ApYdIGDZASpYdoCAZQcIWHaAgGUHCFh2gH6NeiEXEZEa1CMXEalPPXIRkblu1Au5ZQcIWHaAgGUH\n",
       "qGDZAQKWHSBg2QEClh0gYNkB+jXqhVxERGpQj1xEpD71yEVE5rpRL+SWHSBg2QEClh2ggmUHCFh2\n",
       "gIBlBwhYdoCAZQfo16gXchERqUE9chGR+tQjFxGZ64ZcyFsLh/t6XVl2gIBlBwhYdoAKlh0gYNkB\n",
       "ApYdIGDZAQKWHaBfw14jvwFaJ0BrP2iNDfm1RURkmlrQeii03g2tFdC6HFrHQmuX7GAiIg3WqP2L\n",
       "pTCtMWg9EVqfhdYqaJ0DrZdAa8u8eCIijdTUQj7p4c2hdQS0vgut26F1MrQOgdYw2j42hNeoy7ID\n",
       "BCw7QAXLDhCw7AAByw4QsOwAAcsOUGE2HLUydheMfRnGngHsAVwMHA+shNa/QGv31HgiIvJXNTcP\n",
       "Wo+C1keh9Udo/Rxa/wda281MNBGRxpoNrZWuT1sAraXQOh1aq6H1dWg9p4GHMoqIzIS5UMgnzWJb\n",
       "aP09tC6A1p+g9QloPWYahzLa9DMNnGUHCFh2gAqWHSBg2QEClh0gYNkBApYdoMJs6JHXMXYHjP0H\n",
       "jB0IPB64DfgKcFlxKOPOuflERJpnCXAu8FvgMuCYYBoDVgMXFbfjKuY1Q5sHrTFoPal0KOMPdCij\n",
       "iMwh066dOwL7FPe3Aq7EjywpM+CMYYTp4SXahzKeVRzKeNIQD2UUEZkJA6+d3wIO7XjMgDMzwnR5\n",
       "uR2h9WZoXQyta6D1fmjt1jGRDTdTTyw7QMCyA1Sw7AAByw4QsOwAAcsOELDsABUG2iMfB/YFLgxe\n",
       "5An48d9nAXvWmOcMGvsjjH0Mxh4FPBvYHDgfWj+D1ut0KKOIzBW9Hu2xFXAe8H58rbxsa2ADsBZY\n",
       "Cvwr0LnmC17wk0+U1VoAHAa8DHg6sAJYg2dv3+7qGK47bj2MNepwIRGZ1brWzl4K62bAd4CzgY/3\n",
       "MP3VwGOAVUGYU4CVxfAdwHJ8AQETmzVDGt7tGfDEXeBzvwO2gP/7WFi8GN55jQ+fuBcsWASvvsWH\n",
       "T3sILFgML1jjw2fuAPMXweEtH/7RfWDeIjhkHrAWzrkHNq6Dp63y4TMWwoZ18LfX+/CXtoF718HL\n",
       "/we4C054IKy/G95yCXA3HLcrrFsPH/mFD79sb1izHr5+gQ/v9Ri44x644RwY2zj8398oDs8DNlwI\n",
       "bAWHHQr33Ry+/DsffufjYPPN4bjLgbvh2IfD+nvg+AuBdXDEI+Gu9XDG+T5+18fCbevh9h8VC/4G\n",
       "vD8NN2TYgKOL4ZXAu5lmIR/Di+9twD9WTLMD8Ce8UO+PHw44HkzXgDXyTRgTv8gBaW2Gt3E2B7ao\n",
       "uE0x7vSHwJF3AIuBRcXP8i167B7g7tJtXcfwVI/3MO0/7AEn/BK4t3Tb0DE81W3jDG2lGOHn1xrD\n",
       "f09bAVsWP3u932269fhW3F+KW8f9L+8AR6xm08+r82f7/gImftdVP+uO63jszXvCx36Df2bl28bg\n",
       "sT7GjW2s+oCmYAz8uzdtRvMyQQ+1c0GXGTwReAlwCX5oIcA/Aw8q7n8GeD7wOvwLuxY4ss+wc8TY\n",
       "PXhhvbPPGRgcdV7vk7fGgIX0XvSrHt+meh5P3QE4Av97iW7zpxi3AJgHrV6Lfq8LiA3wjZ3heeuJ\n",
       "C+8G4mIbFF/uAK4PHu98zhoYu7fLB2Jw5HldpilpzWPT4j5V4a96bKvqcQfdH3gW/jmVb/OCx7qN\n",
       "Cx5vQe3if/ZmsPRWNm1tTjXcbdq7+lyozHrDXENu4hq5DEWr/eWfqtjXWTC0b3cRF+g1xQJVhuKv\n",
       "n2+dBcNCJm+ZbsnkrdMtexxXHl6Mb4X0sxBYg/89rcNXxNZ33Hp57N4Z2vKc9hq5yACMbcTXyFRc\n",
       "56S/fr7JWvPYtG3Zy0Lg/qXhhaXbZh3D3R5bAK1+FwJVj63vZf131Au50byemKFMvTKal8tQpl4Y\n",
       "A880tpG/tsD6YkwrU2seE0W97kJgqse6GvVCLiIyIGMb8dbMugHP+P0Dnt+06NhqEZH65trZD0VE\n",
       "pNOoF3LLDhCw7AAByw5QwbIDBCw7QMCyAwQsO0DAsgP0a9QLuYiI1KAeuYhIfeqRi4jMdaNeyC07\n",
       "QMCyAwQsO0AFyw4QsOwAAcsOELDsAAHLDtCvUS/kIiJSg3rkIiL1qUcuIjLXjXoht+wAAcsOELDs\n",
       "ABUsO0DAsgMELDtAwLIDBCw7QL9GvZCLiEgN6pGLiNSnHrmIyFw36oXcsgMELDtAwLIDVLDsAAHL\n",
       "DhCw7AAByw4QsOwA/Rr1Qi4iIjWoRy4iUp965CIic92oF3LLDhCw7AAByw5QwbIDBCw7QMCyAwQs\n",
       "O0DAsgP0a9QLuYiI1KAeuYhIfeqRi4jMdaNeyC07QMCyAwQsO0AFyw4QsOwAAcsOELDsAAHLDtCv\n",
       "US/kIiJSg3rkIiL1qUcuIjLXdSvkS4Bzgd8ClwHHVEz3CeD3wMXAvgNLN/MsO0DAsgMELDtABcsO\n",
       "ELDsAAHLDhCw7AAByw7QrwVdxt8D/COwHNgK+DVwDvC70jSHA7sCDwceB5wIHDDwpCIiMhDfAg7t\n",
       "eOzTwBGl4SuAHYLnqkcuIlLfQHvk43jb5MKOx3cGrisNXw/sUmO+IiIyDd1aK21bAV8D3gj8JRg/\n",
       "1jFctQQ5GVhZ3L8Db9mcVwxb8XOYw/sAH098/Wi4/VhT8pSzNCVPe1if3+z9/N5E/ve/c7gpf08G\n",
       "HF0Mr2RANgO+j//iI58GjiwNz6bWimUHCFh2gIBlB6hg2QEClh0gYNkBApYdIGDZASpMu3aOAZ8H\n",
       "jp9imsOBs4r7BwA/n6kwIiIjaNq180nARnwT6KLithR4bXFr+yRwFX744aNnKoyIyAhqVO1sVJiC\n",
       "ZQcIWHaAgGUHqGDZAQKWHSBg2QEClh0gYNkBKug/O0VEZHCauEYuItJ0XWtnr4cfisjgrQLumx1C\n",
       "GuN2YLvsEN00cY3csgMELDtAwLIDVLDsAAGrMe2wvhM2pNepw7IDBCz59av+HtQjFxGRwWniGrlI\n",
       "Jn0npExr5CIio2rUC7llBwhYdoCAZQeoYNkBApYdIGDZAQKWHSBg2QH6NeqFXERmxonAcdOcx8nA\n",
       "+6YfRQZJ/UCRyZr8nVgJPDk5w0nAe5MzDJN65CIyUC02PT112zD//6Qqg5SMeiG37AAByw4QsOwA\n",
       "FSw7QMCyAwSs5vRfAB4EnAn8GXgrfvK8VwLXAD8spvsqcBN+bYEfA3uW5nEyE20Rwy8482bgZuBG\n",
       "4IM1MwG8Gr828G3At4EHlsYdX8x7NXAJsFfx+OH4NYfvLDK8ZYr5Wx+ZGmHUC7lIg7Vag7nV9lLg\n",
       "WuCZwNbAV4rHDwIeATytGP4ufr3e+wO/Ab5UDs/klsAOwH2AnYBX4Rep2aZGpicD/w94AV7ArwFO\n",
       "L8Y9DTgQv27wNsU0txXj/hN4TfHaewH/VeM1JdDkfqBIhiZ/J65mokc+jq+Rj08x/bbFNFsXwycx\n",
       "eY18LZNXHG8G9u+Sodwj/08mr8VvCazHtxwOAa7EL/7euXJ6DROFvOnUIxeRGVe+Nu88vLBehbcz\n",
       "ri4e377iubfhhb5tLX4JyV6118Lb1hTz3Bk4F78mwqfwBcRnmFig/B3eXlmJX0btgBqvOWuMeiG3\n",
       "7AAByw4QsOwAFSw7QMCyAwSsj+dEa4Hlx14MPBs4FG9nPKR4fKxi+k6La+a5kclbBFsC9wNuKIZP\n",
       "APbD+/S74X19gF8Bz8XbP99iok0UsZqZGmPUC7mIxG4GHjbF+K2AdfgZHLfE+9dlY0z/iJPyPE4D\n",
       "XgE8ClhUvN7P8V7+fnhbZTN8Tf9uYEMx/GJ8QbMB33G7YZqZRl6T+4EiGZr8nXg23spYhR/psYHJ\n",
       "K35b4mu4d+JtlZcW0zy0GF/ubxtecMvKPfgqnceRvxZv5dwGnIHvOKWYz8V4ob4FP+pmC7yQn128\n",
       "h9XAhcATurxmpr575MPUqDAiDaDvhJRpZ2efLDtAwLIDBCw7QAXLDhCw7AAByw4QsOwAAcsO0K9R\n",
       "L+Qikuu3eEuk83ZUZiipps1Ikcn0nZAytVZEREbVqBdyyw4QsOwAAcsOUMGyAwQsO0DAsgMELDtA\n",
       "wLID9GvUC7mIiNSgfqDIZPpOSJl65CIio2rUC7llBwhYdoCAZQeoYNkBApYdIGBDfJ3yibUuw099\n",
       "G3lTx7RVVuLncxkGG9LrDFwvhfxz+HkXLq0Yb/i/v15U3KZ7nT4RmRv2Bs6f5jw6z2sufToQ2Jep\n",
       "C/kZPcxHH4bIZHPtO2H0tpZdZ9pezskyV8xoj/wC4PYu0+i6eiJzx7H4ZdzK/rW4HQ1cjp8sawV+\n",
       "0YYqK5loi2yOX/5tFf7fnI/tI9ci4OP4qWtvwC/vtrAYtz3wHbxW3cbkLYFj8cu83QlcwegsGDYx\n",
       "TvUa+cH4L+5i4CwmX7evrIlrH5YdIGDZAQKWHaCCZQcIWI1ph/WdsJrTPwi/cEP7wg/z8fOB749f\n",
       "pKF97vGDiun2Lb1OeS27vDb9Qfy6ntsCuxTjOs+IGCnP473AT/GivT3wEybOjvgB4MQi63zgicXj\n",
       "uxevs2PpvbXP0NjJesgzk/peIx/E1bB/AyzBzwO8FD+15W4V056ML6XBL9i6HL9qB0z8Eoc5vE/y\n",
       "60fDdBmv4YnhufD5VU+/jHMZhGUcUiPPeXjhWwG8A3gnXkhb+Klhz+qY/gd4+3Ub/POgNL588YiX\n",
       "4mvQdxS3C5m8ZlyVpzz+VcXt1mL4m8DrgXfhVxDaFV/pXIGfwtbwNfFFwIvwlc0fTfF6Tfh7at8/\n",
       "uri/kgEap3qNvNPVwHbB401cIxfJ1OTvxOuYKNonAe8p7i/FL+hwG97GWFcaZ1Svkd8F7FEa9zTq\n",
       "98jXdszjEcXrg289/H+8iK/A2yltR+Et4lX4BSoe2MPrZpjx85GPU13Id2CiR74/1UuQJv/RimRo\n",
       "8nfi/njh3Bkv2Lvja7Zrgefh7QvwteJ2e8OoLuR/wIt326upX8ivwhckbYcxca3Qsr3wI+06e+Fb\n",
       "A6cCn+/hdTPM6M7O0/C+1O74L/6V+JU6XluMfz5e5JfjOyKO7GGeTWHZAQKWHSBg2QEqWHaAgGUH\n",
       "CFgfz7kF3+w/GS/CV+I7FhfirY2NeFE9rMf5fQVv1bR75G/vI9Np+OHN7R75u/CrAQE8E2+tjOE7\n",
       "NTcUt93wgr4IX3tvXwYuYn1kaoReeuTdzgv8qeImInNLe+21fSHjPwPH4EV5EXAm8O2O51StPb4H\n",
       "+DS+Bn0D3lt/Rs087wfuA1xSDH+leAy8iJ+Ab0ncjtekHwOPxHeE7gHcg+8gnepIG+miyZuRIhn0\n",
       "nZAynWtFRGRUjXoht+wAAcsOELDsABUsO0DAsgMELDtAwIqfDyK+1NudeC89I9OsM4jjyEVE+nUt\n",
       "fjSJzBLqB4pMpu+ElKlHLiIyqka9kFt2gIBlBwhYdoAKlh0gYNkBApYdIGDZAQKWHaBfo17IRUSk\n",
       "BvUDRSaba98Jo/crBHVOK8lnPxQRieydHWBUjHprxbIDBCw7QMCyA1Sw7AAByw4QsOwAgX26TzJ0\n",
       "1jE8xiy5aM6oF3IR2dQwrhC0e49Z3o6f9fDO4nnP7Rj/6lKe3zJxkYslwDeAP+En+TqheHwZEyfa\n",
       "Aj+z60YmauF5+PlbfoJfNOOhwCuY+j0/Bz9p4Ooi69OAFwC/6pjuzfj1Gma1udYPFJmupn4nhnGF\n",
       "oMvo7QpBz2fi6j4vBP6CnzobvFheDzymGH5YkX0+fhGJj+ILkEXAE4pp3k33Qr4SP8nWPLz9PNV7\n",
       "3h+/UEZ7gbUTvpBaiJ+z/RGl17oI+Nsp3uuMn498EBoVRqQBmvyduAC/qg/AU/E1zcg38TMiwtSF\n",
       "fAWTT3nb6/nIO10EPKu4/33gH4JpHo+viUcdh2VMXcjPLaaZSvk9fwZfYEROZOLsjHvhWyObTTFf\n",
       "/UNQnyw7QMCyAwQsO0AFyw4QsEHNqAWtQdz6zHQqE6ewfhHwpeJ+5xWCDgfu18P8dmJy4d62xxwv\n",
       "w4v37cVtb/xc5OBr9iuC5ywBrsELdB1W/OxcwEz1nqsyAJyC/+7AF4pfxk+lO3CjXshFGmsMxgZx\n",
       "6/Plv4YXtp3xvvSpeIvi68CHgQcA98UvB9fLa9yEtz3aHtDDcx4MfBa/Lud2xetdVnq96/DzkHe6\n",
       "jokWS6e/4NcebdsxmKa8BtztPVdlAC/+6/F2zFFM3hKYtZq8GSmSoenfibOAc4BfF8NbA/fihWkM\n",
       "X1NdQ2+Xevsg3n9u98gvoXtrZU/8Wp+74UX5Ffga7SuL8c/H++yPLvLsihfwefjOx4/gRXsxEz3y\n",
       "p+BXP1qCXzD622zaWnlVKUO39/xYfC39ycU8dmbyjtx3Fu/1913eK6i1IiIz4FR8J96pxXD5CkGr\n",
       "8LXMOlcIugYv7t/DrzzUrUBdjveffwb8EW+r/Hdp/NeAfyny3YkfpXJfvDA/Cy/s1+ILjBcWz/kh\n",
       "3uK4BPglfpWjzhzl4W7v+Zf4AuZ4fKfnuUze8vgC3h//Ypf3Oms0ce3DsgMELDtAwLIDVLDsAAGr\n",
       "Me2wvhM2pNepw7IDBGwG5rk5vpB5WA/Tao1cRKSBXgf8guodorNOE9fIRTLpO9GsKwQN2kq8lfSo\n",
       "HqfXceQis5C+E1Km1kqfLDtAwLIDBCw7QAXLDhCw7AAByw4QsOwAAcsO0K9RL+QiIlKDNiNFJtN3\n",
       "QsrUWhERGVWjXsgtO0DAsgMELDtABcsOELAa096Or23pplsL/3voy6gXcpFM2zFx8YKZvB0ypNdR\n",
       "pundtmMGfQ64Gbh0imk+gZ9L4GImztPbqTXgXCIio2AgtfNAvDhXFfLD8ZPrADwOP+PXjIURERkx\n",
       "A6ud41QX8k8DR5SGr2DiCh4zEmaALDtAwLIDBCw7QAXLDhCw7AAByw4QsOwAAcsOUKFr7RxEj3xn\n",
       "Jp+O8npm/7/WiojMGgsGNJ+xjuGqJcjJ+PkHwE/5uBw/RzFMLA2HPUyX8Rr2W5PylIfpMl7Dzfz8\n",
       "2o81JU97mC7jhzFs+EWuYaJeDsQ4U7dWjiwNz6bWiohI0w2ltXIGfl09gAPwNe2bBzDfYbDsAAHL\n",
       "DhCw7AAVLDtAwLIDBCw7QMCyAwQsO0C/emmtnAYcjF/w9Drg3UxcCfoz+BErh+NX2V6DXy1DRETm\n",
       "ILVWRETqG0prRUREEo16IbfsAAHLDhCw7AAVLDtAwLIDBCw7QMCyAwQsO0C/Rr2Qi4hIDeqRi4jU\n",
       "px65iMhcN+qF3LIDBCw7QMCyA1Sw7AAByw4QsOwAAcsOELDsAP0a9UIuIiI1qEcuIlKfeuQiInPd\n",
       "qBdyyw4QsOwAAcsOUMGyAwQsO0DAsgMELDtAwLID9GvUC7mIiNSgHrmISH3qkYuIzHWjXsgtO0DA\n",
       "sgMELDtABcsOELDsAAHLDhCw7AAByw7Qr1Ev5CIiUoN65CIi9alHLiIy1416IbfsAAHLDhCw7AAV\n",
       "LDtAwLIDBCw7QMCyAwQsO0C/Rr2Qi4hIDeqRi4jUpx65iMhcN+qF3LIDBCw7QMCyA1Sw7AAByw4Q\n",
       "sOwAAcsOELDsAP0a9UIuIiI1qEcuIlKfeuQiInPdqBdyyw4QsOwAAcsOUMGyAwQsO0DAsgMELDtA\n",
       "wLID9GvUC7mIiNSgHrmISH0D6ZE/HbgC+D1wbDDegNXARcXtuN7ziYjITJsPXAWMA5sBy4E9OqYx\n",
       "4Iwe5tXENXLLDhCw7AAByw5QwbIDBCw7QMCyAwQsO0DAsgNUmPYa+f54IV8J3AOcDjwnmG6sbjIR\n",
       "ERmO5wP/Xhp+CXBCxzQHA7cBFwNnAXtWzKuJa+QiIk3XtXYumO4MgN8AS4C1wFLgW8BuPTxPREQG\n",
       "oFshvwEv0m1LgOs7pvlz6f7ZwL8B2wGrgvmdjLdpAO7Ae+7nFcNW/Bzm8D7AxxNfPxpuP9aUPOUs\n",
       "TcnTHtbnN3s/vzeR//3vHG7K35MBRxfDKxmABcAKfGfnQuKdnTsw0SPff4oXbmJrxbIDBCw7QMCy\n",
       "A1Sw7AAByw4QsOwAAcsOELDsABUGUjuXAlfiOz3fUTz22uIG8HrgMrzI/xQ4YCbDiIiMmEbVzkaF\n",
       "ERGZJXTSrC4sO0DAsgMELDtABcsOELDsAAHLDhCw7AAByw7Qr1Ev5CIiUoNaKyIi9am1IiIy1416\n",
       "IbfsAAHLDhCw7AAVLDtAwLIDBCw7QMCyAwQsO0C/Rr2Qi4hIDeqRi4jUpx65iMhcN+qF3LIDBCw7\n",
       "QMCyA1Sw7AAByw4QsOwAAcsOELDsAP0a9UIuIjLrdTv74UC11CcXEamlaVftUREXEalPOzu7sOwA\n",
       "AcsOELDsABUsO0DAsgMELDtAwLIDBCw7QL+GudbeYhnndpmmlzyDmgauYBseweqeph0Wz3RHdoxJ\n",
       "rmDbjkzDxxHsAAAFnUlEQVStadyf7vMn7l/OduzJKiZ/3lX3pxo3qPvt39Xtpay93mZu+kvZkUdy\n",
       "E931stU8mGku4YH8DTd2TF/1s5dppj/tRSxhX67rSFpVS6LHe32s3rTLeOMU85nyRWZCi2Uc2tN0\n",
       "w5umiZrWEus0vUI32AKatxCpvj9W+tnrbSanL2eaynBXojbNVvVz2NNGdaOqlvQ67fSev4zjaVBd\n",
       "mK2FVUQkk3rkXVh2gIBlBwhYdoAKlh0gYNkBApYdIGDZAQKWHaBfo17IRUSkBrVWRETqU2tFRGSu\n",
       "G/VCbtkBApYdIGDZASpYdoCAZQcIWHaAgGUHCFh2gH6NeiEXEZEa1CMXEalPPXIRkblu1Au5ZQcI\n",
       "WHaAgGUHqGDZAQKWHSBg2QEClh0gYNkB+jXqhVxERGpQj1xEpD71yEVE5rpeCvnTgSuA3wPHVkzz\n",
       "iWL8xcC+g4k2FJYdIGDZAQKWHaCCZQcIWHaAgGUHCFh2gIBlB+hXt0I+H/gkXsz3BI4C9uiY5nBg\n",
       "V+DhwGuAEweccSbtkx0goEy9a2IuZeqNMg1Qt0K+P3AVsBK4BzgdeE7HNM8GTinuXwhsC+wwuIgz\n",
       "atvsAAFl6l0TcylTb5RpgLoV8p1h0hUzri8e6zbNLtOPJiIivehWyHs90qTz6hWz5QiV8ewAgfHs\n",
       "AIHx7AAVxrMDBMazAwTGswMExrMDBMazA/Sr2+WDDgCW4T1ygHcAG4EPlab5NHAe3nYB3zF6MHBz\n",
       "x7yuAh7Wf1QRkZG0At8P2bcFxUzGgYXAcuKdnWcV9w8Afj6dFxQRkcFbClyJr1G/o3jstcWt7ZPF\n",
       "+IuBRw81nYiIiIiITK2Xfygats/hPfxLs4OULAHOBX4LXAYckxsHgMX4IaXLgcuBD+TGmWQ+cBFw\n",
       "ZnaQwkrgEjzTL3KjTLIt8DXgd/hneEBuHHbHf0ft22qa8bf+Dvy7dylwKrAoNw4Ab8TzXFbcTzMf\n",
       "b7mMA5sR99gzHIj/B2qTCvmOTPxDwlZ4O6sJv6stip8L8P0fT0rMUvZm4EvAGdlBClcD22WHCJwC\n",
       "vLK4vwDYJjFLp3nATfhKTKZx4A9MFO8vAy9PS+P2xuvTYryOnsMUB4vM9LlWevmHogwXALdnh+jw\n",
       "R3xBB/AXfA1qp7w4f7W2+LkQ/4NalZilbRd8J/t/0P3Iq2FqUhbwon0gvgUKcC++BtwUT8EPpriu\n",
       "24Qz7E68Pm2BL+y2AG5ITQSPwLeG7wY2AD8Gnlc18UwX8l7+oUg2NY5vMVyYnAP8b2Q53oo6F988\n",
       "z3Y88Fb8UNimaAE/BH4FvDo5S9tDgFuAk4DfAP/OxBZWExyJtzGyrQI+ClwL3AjcgX+WmS7DF8Lb\n",
       "4Z/ZM5jiHy1nupDPln8MapKt8J7mG/E182wb8ZbPLsBB5J9Y6JnAn/D+apPWgJ+IL3yXAq/Hv4TZ\n",
       "FuBHkf1b8XMN8PbURBMWAs8CvpodBG9ZvAlfgdoJ/w6+ODMQvl/xQ8APgLPxv/fKFZeZLuQ3MLn/\n",
       "tQRfK5fYZsDXgS8C30rO0mk18F1gv+QcT8DP73M1cBrwZODzqYncTcXPW4Bv4m3FbNcXt18Ww1+j\n",
       "OYcHLwV+jf++su0H/BS4DW8/fQP/O8v2OTzbwfhWwpVZQXr5h6Is4zRrZ+cYXpCOzw5Ssj0TJxLa\n",
       "HDgfODQvziYOphlHrWwBbF3c3xL4CXBYXpxJzgd2K+4vY/J/ZWc6nfwdim2PwlsZm+Pfw1Pwraps\n",
       "Dyh+PgjfZ3afxCzhPxRlOw3vha3De/ivyI0D+NEgG/GFXfvQrKdP+YyZ90i8t7ocP7TurblxNnEw\n",
       "zThq5SH472g5XhCa8ncOXqR+if+z3jdoxlErWwK3MrHwa4K3MXH44Sn41nG28/FMy4FDkrOIiIiI\n",
       "iIiIiIiIiIiIiIiIiIiIiIiIiIiIyKD8L7vhwy4GbBkxAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e5821d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "perf[['train_loss','valid_loss','valid_accuracy']].plot(title='Performance during Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02764352,  0.02628479,  0.01885541,  0.02287088,  0.07707576,\n",
       "          0.03561188,  0.02735219,  0.00849575,  0.01933375,  0.02321376,\n",
       "          0.01439499,  0.05123205,  0.0622489 ,  0.03089152,  0.03661775,\n",
       "          0.01318237,  0.37626788,  0.03908256,  0.01377889,  0.04675278,\n",
       "          0.02881263],\n",
       "        [ 0.02777688,  0.03029649,  0.02068442,  0.0244167 ,  0.07876992,\n",
       "          0.04000157,  0.03016515,  0.00919801,  0.01891897,  0.02791033,\n",
       "          0.01408748,  0.05496172,  0.05925034,  0.03395918,  0.03973318,\n",
       "          0.01385091,  0.34407005,  0.03654079,  0.01552516,  0.05408347,\n",
       "          0.02579927],\n",
       "        [ 0.03036228,  0.01792865,  0.01538878,  0.02011583,  0.07907888,\n",
       "          0.02471378,  0.02122433,  0.00909552,  0.0265069 ,  0.01309099,\n",
       "          0.02111524,  0.04027713,  0.08546366,  0.02257629,  0.02723236,\n",
       "          0.01491936,  0.38345408,  0.05359882,  0.01157298,  0.02782603,\n",
       "          0.05445808],\n",
       "        [ 0.02804004,  0.02520437,  0.01859072,  0.02268346,  0.07850766,\n",
       "          0.03433179,  0.0265749 ,  0.00862991,  0.02015091,  0.0219515 ,\n",
       "          0.01506264,  0.04958793,  0.06501573,  0.03008359,  0.03563373,\n",
       "          0.01347165,  0.37644097,  0.04076494,  0.01365555,  0.04424633,\n",
       "          0.03137167],\n",
       "        [ 0.02792295,  0.03169078,  0.02150829,  0.02511968,  0.07812396,\n",
       "          0.04155837,  0.03139047,  0.00954031,  0.01880667,  0.02973325,\n",
       "          0.01408842,  0.05669688,  0.05778428,  0.0351004 ,  0.04098289,\n",
       "          0.0141418 ,  0.33215287,  0.03604433,  0.01616723,  0.05663788,\n",
       "          0.02480827],\n",
       "        [ 0.02769068,  0.02791579,  0.01964465,  0.02355511,  0.07736338,\n",
       "          0.03752485,  0.0285932 ,  0.008752  ,  0.01903817,  0.02521626,\n",
       "          0.01419557,  0.05314213,  0.06067515,  0.03225684,  0.03806419,\n",
       "          0.01341583,  0.3633247 ,  0.03795867,  0.01449168,  0.04988234,\n",
       "          0.02729879],\n",
       "        [ 0.0278144 ,  0.0274852 ,  0.01951299,  0.02343384,  0.07771249,\n",
       "          0.03706888,  0.0282795 ,  0.00875518,  0.0192652 ,  0.02470457,\n",
       "          0.01434812,  0.05242082,  0.06131205,  0.0318651 ,  0.03771704,\n",
       "          0.0134594 ,  0.36507344,  0.03845995,  0.01436195,  0.04904712,\n",
       "          0.0279028 ],\n",
       "        [ 0.03151445,  0.01557923,  0.01430191,  0.01933404,  0.07524231,\n",
       "          0.02163276,  0.01943332,  0.00920186,  0.02967632,  0.01067748,\n",
       "          0.02399755,  0.03704457,  0.09117372,  0.01990927,  0.02459038,\n",
       "          0.01547867,  0.38068792,  0.06112231,  0.01076849,  0.02335426,\n",
       "          0.06527919],\n",
       "        [ 0.02996177,  0.01951193,  0.01663035,  0.0209301 ,  0.08463057,\n",
       "          0.02736706,  0.02263181,  0.00927176,  0.02473052,  0.01537049,\n",
       "          0.01967805,  0.04205771,  0.08244579,  0.0248726 ,  0.02978989,\n",
       "          0.01499809,  0.37226611,  0.04968822,  0.01245136,  0.03140791,\n",
       "          0.0493079 ],\n",
       "        [ 0.02784749,  0.03091436,  0.02098864,  0.02466599,  0.0788471 ,\n",
       "          0.04059598,  0.03061973,  0.00934651,  0.01895213,  0.02861024,\n",
       "          0.01411654,  0.05542601,  0.05884723,  0.03438807,  0.04020149,\n",
       "          0.01399104,  0.33891118,  0.03631966,  0.01581182,  0.05514216,\n",
       "          0.02545663]], dtype=float32), array([[ 3],\n",
       "        [ 2],\n",
       "        [ 1],\n",
       "        [ 4],\n",
       "        [ 6],\n",
       "        [ 7],\n",
       "        [ 9],\n",
       "        [12],\n",
       "        [10],\n",
       "        [ 2]]), array([ 5, 16, 20, 20, 17,  2, 16, 16,  8,  4], dtype=int32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs(X_val[0:10]),np.argmax(X_val[0:10], axis=1), y_val[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
