{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the Images (one Tumor per Time)\n",
    "\n",
    "#### Creation of Training and Testset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.107199192047\n",
      "   (500, 1, 48, 48) y (500,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['VDHZHLF4YEWKJ3KRMI4CGXV4JE======_ep2d_diff_3scan_p3_m128_ADC_3_13.dcm',\n",
       " 'OPS36EIZVSPOQLUNVC4WA3VENA======_resolve_3scan_trace_tra_176_p2_ADC_3_13.dcm',\n",
       " 'OPS36EIZVSPOQLUNVC4WA3VENA======_resolve_3scan_trace_tra_176_p2_ADC_3_15.dcm']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "#Inselspital\n",
    "with gzip.open('GBM_tumors.pickle.gz') as f:\n",
    "    Names,X,Y = pickle.load(f)\n",
    "print (\"Loaded data in \" + str(time.time() - start))\n",
    "print (\"   \" + str(X.shape) + \" y \" + str(Y.shape))\n",
    "\n",
    "\n",
    "gmb_valid = 306\n",
    "gbm_test = 408\n",
    "Y_test = Y[gbm_test:]\n",
    "\n",
    "Names[(gbm_test-1):(gbm_test+2)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_9.dcm',\n",
       " 'ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_11.dcm',\n",
       " 'ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_12.dcm',\n",
       " 'ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_13.dcm',\n",
       " 'ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_14.dcm',\n",
       " 'ZBD7HFU2HL6GJF4ESYT6QGNXE4======_ep2d_diff_3scan_trace_p3_ADC_3_8.dcm']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Names[300:306]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data in 0.0960810184479\n",
      "   (429, 1, 48, 48) y (429,)\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "#Inselspital\n",
    "with gzip.open('META_tumors.pickle.gz') as f:\n",
    "    Names,X,Y = pickle.load(f)\n",
    "print (\"Loaded data in \" + str(time.time() - start))\n",
    "print (\"   \" + str(X.shape) + \" y \" + str(Y.shape))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "400.0 / 500.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first Try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1110, 1, 256, 256)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasagne import layers\n",
    "from lasagne import nonlinearities\n",
    "from nolearn.lasagne import BatchIterator\n",
    "from lasagne import nonlinearities\n",
    "from nolearn.lasagne import NeuralNet\n",
    "import time\n",
    "\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "################ Pickle with an updated recursion limit\n",
    "import pickle\n",
    "import sys\n",
    "sys.setrecursionlimit(10000)\n",
    "\n",
    "PIXELS = 48\n",
    "CLASSES = 2\n",
    "DEBUG = True\n",
    "\n",
    "class MyNeuralNet(NeuralNet):\n",
    "\n",
    "    def train_test_split(self, X, y, eval_size):\n",
    "        print(\"Doing the Training Testing Split\")\n",
    "        train_indices = range(0,192)\n",
    "        valid_indices = range(192,240)\n",
    "        #valid_indices = range(0,80)\n",
    "        #train_indices = range(80,240)\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_valid, y_valid = X[valid_indices], y[valid_indices]\n",
    "        return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "#   A BatchIterator which cut's part of the training set\n",
    "class SegmentationBatchIterator(BatchIterator):\n",
    "\n",
    "    def __init__(self, batch_size, nClasses, nPixels):  #Python is so ugly!\n",
    "        super(self.__class__, self).__init__(batch_size) # <----      Das sieht doch zum kotzen aus!\n",
    "        self.nClasses = nClasses\n",
    "        self.nPixels = nPixels\n",
    "        # We should initialize with 0 but then there is a possibility of division by zero\n",
    "        # but we don't make a big mistake by initialising with 1\n",
    "        self.freq = np.ones(nClasses, dtype=np.int64)\n",
    "        if DEBUG: print(\"------------   Constructor has been called --------------------- \")\n",
    "\n",
    "\n",
    "    def transform(self, Xb, yb):\n",
    "        if  not yb == None: #Training or Validation\n",
    "            retYs = np.zeros(len(yb), dtype='uint8')\n",
    "            retX = np.zeros((Xb.shape[0], Xb.shape[1], PIXELS, PIXELS), dtype='float32')\n",
    "            for b in range(len(yb)):\n",
    "                for i in range(1000): #Trying to sample 1000 times.\n",
    "                    x,y = np.random.randint(PIXELS/2, 160-PIXELS/2,2)\n",
    "                    example = np.random.randint(len(yb)) #Choose a random example from the training set\n",
    "                    rety = yb[example,:,x,y]\n",
    "                    if (rety > 0): #Only for one class\n",
    "                      rety = 1\n",
    "                    rel = float(self.freq[rety]) / self.freq.sum()\n",
    "                    ap = (1.0 - rel + 0.2)**8\n",
    "                    goal = 1.0 / self.nClasses\n",
    "                    if (rel < goal + 0.05):\n",
    "                        break\n",
    "                self.freq[rety] = self.freq[rety] + 1\n",
    "                retYs[example] = rety\n",
    "                retX[example,:,:,:] = Xb[example,:,(x-PIXELS/2):(x+PIXELS/2),(y-PIXELS/2):(y+PIXELS/2)]\n",
    "            if DEBUG: print(str(i) + \" \" + str(retYs.mean()) + \" batchsize \" + str(retX.shape) + \"   freq= \" + str(self.freq) + \" sum \" + str(self.freq.sum()))\n",
    "            #print(\"Made Patches around \" + str(x) + \",\" + str(y) + \" width \" +  str(retX.shape) + \"  \" + str(retY.shape))\n",
    "\n",
    "            ##### Plotting\n",
    "            #import cv2\n",
    "            #cv2.imshow('Test', retX[0,0,:,:])\n",
    "            #cv2.waitKey(100)\n",
    "            return retX,retYs#TODO check if x,y are correct\n",
    "        else:\n",
    "            if DEBUG: print(\"Made Patches around \")\n",
    "            return Xb,yb\n",
    "\n",
    "\n",
    "\n",
    "net1 = MyNeuralNet(\n",
    "    # Geometrie of the network\n",
    "    layers=[\n",
    "        ('input', layers.InputLayer),\n",
    "        ('conv1', layers.Conv2DLayer),\n",
    "        ('pool1', layers.MaxPool2DLayer),\n",
    "        ('dropout1', layers.DropoutLayer),\n",
    "        ('conv2', layers.Conv2DLayer),\n",
    "        ('pool2', layers.MaxPool2DLayer),\n",
    "        ('dropout2', layers.DropoutLayer),\n",
    "        ('hidden3', layers.DenseLayer),\n",
    "        ('dropout3', layers.DropoutLayer),\n",
    "        ('hidden4', layers.DenseLayer),\n",
    "        ('output', layers.DenseLayer),\n",
    "        ],\n",
    "    input_shape=(None, 1, PIXELS, PIXELS),\n",
    "    conv1_num_filters=32, conv1_filter_size=(5, 5), pool1_ds=(2, 2), dropout1_p=0.2,\n",
    "    conv2_num_filters=64, conv2_filter_size=(3, 3), pool2_ds=(2, 2), dropout2_p=0.2,\n",
    "    hidden3_num_units=256, dropout3_p=0.5,\n",
    "    hidden4_num_units=128,\n",
    "    output_num_units=CLASSES, output_nonlinearity=nonlinearities.softmax,\n",
    "\n",
    "    # learning rate parameters\n",
    "    update_learning_rate=0.001,\n",
    "    update_momentum=0.09,\n",
    "    regression=False,\n",
    "    # We only train for 10 epochs\n",
    "    max_epochs=10,\n",
    "    verbose=1,\n",
    "\n",
    "    # Training test-set split\n",
    "    eval_size = 0.2,\n",
    "\n",
    "    batch_iterator_train = SegmentationBatchIterator(128, CLASSES, PIXELS),\n",
    "    batch_iterator_test=SegmentationBatchIterator(128, CLASSES, PIXELS)\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Setting the new batch iterator\n",
    "#net1.batch_iterator_train = SimpleBatchIterator(batch_size=10)\n",
    "#net1.batch_iterator_test = SimpleBatchIterator(batch_size=10)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    with gzip.open('data/data.pkl.gz', 'rb') as f:\n",
    "        X,Y = pickle.load(f)\n",
    "    print (\"Loaded data in \" + str(time.time() - start))\n",
    "    print (\"   \" + str(X.shape) + \" y \" + str(Y.shape))\n",
    "    X = X / X.max()\n",
    "    net1.max_epochs = 2\n",
    "    net1.fit(X[0:240,:,:,:],Y[0:240,:,:,:]) #Achtung Zahlen sind noch festcodiert\n",
    "    with open('data/net1.pickle', 'wb') as f:\n",
    "        pickle.dump(net1, f, -1)\n",
    "\n",
    "    start = time.time()\n",
    "    with open('data/net1.pickle', 'rb') as f:\n",
    "        net_pretrain = pickle.load(f)\n",
    "    print (\"Loaded net in \" + str(time.time() - start))\n",
    "\n",
    "    ddd = net1.predict(X[240:241,:,48:(48+48),48:(48+48)])\n",
    "    ddd = net1.predict_proba(X[240:241,:,48:(48+48),48:(48+48)])\n",
    "    print(\"Hallo Gallo\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
